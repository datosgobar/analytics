{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Uso-de-series-en-API-Series-de-Tiempo\" data-toc-modified-id=\"Uso-de-series-en-API-Series-de-Tiempo-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Uso de series en API Series de Tiempo</a></div><div class=\"lev1 toc-item\"><a href=\"#Indice\" data-toc-modified-id=\"Indice-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Indice<span class=\"tocSkip\"></span></a></div><div class=\"lev1 toc-item\"><a href=\"#Resumen-ejecutivo\" data-toc-modified-id=\"Resumen-ejecutivo-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Resumen ejecutivo</a></div><div class=\"lev2 toc-item\"><a href=\"#Origen-de-las-llamadas\" data-toc-modified-id=\"Origen-de-las-llamadas-31\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Origen de las llamadas</a></div><div class=\"lev2 toc-item\"><a href=\"#Sobre-las-fuentes-primarias\" data-toc-modified-id=\"Sobre-las-fuentes-primarias-32\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Sobre las fuentes primarias</a></div><div class=\"lev2 toc-item\"><a href=\"#Estado-de-las-series-publicadas\" data-toc-modified-id=\"Estado-de-las-series-publicadas-33\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Estado de las series publicadas</a></div><div class=\"lev3 toc-item\"><a href=\"#Histogramas-de-las-series-diaras-actualizadas-y-desactualizadas\" data-toc-modified-id=\"Histogramas-de-las-series-diaras-actualizadas-y-desactualizadas-331\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>Histogramas de las series diaras actualizadas y desactualizadas</a></div><div class=\"lev2 toc-item\"><a href=\"#Llamadas-mensuales---Período-completo\" data-toc-modified-id=\"Llamadas-mensuales---Período-completo-34\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Llamadas mensuales - Período completo</a></div><div class=\"lev2 toc-item\"><a href=\"#Números-generales\" data-toc-modified-id=\"Números-generales-35\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Números generales</a></div><div class=\"lev3 toc-item\"><a href=\"#Sobre-las-consultas\" data-toc-modified-id=\"Sobre-las-consultas-351\"><span class=\"toc-item-num\">3.5.1&nbsp;&nbsp;</span>Sobre las consultas</a></div><div class=\"lev3 toc-item\"><a href=\"#Sobre-los-usuarios\" data-toc-modified-id=\"Sobre-los-usuarios-352\"><span class=\"toc-item-num\">3.5.2&nbsp;&nbsp;</span>Sobre los usuarios</a></div><div class=\"lev3 toc-item\"><a href=\"#Series-populares\" data-toc-modified-id=\"Series-populares-353\"><span class=\"toc-item-num\">3.5.3&nbsp;&nbsp;</span>Series populares</a></div><div class=\"lev1 toc-item\"><a href=\"#Cantidad-de-llamadas\" data-toc-modified-id=\"Cantidad-de-llamadas-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Cantidad de llamadas</a></div><div class=\"lev2 toc-item\"><a href=\"#Perfil-de-las-series\" data-toc-modified-id=\"Perfil-de-las-series-41\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Perfil de las series</a></div><div class=\"lev3 toc-item\"><a href=\"#Perfil-de-series-diarias\" data-toc-modified-id=\"Perfil-de-series-diarias-411\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>Perfil de series diarias</a></div><div class=\"lev1 toc-item\"><a href=\"#Cantidad-de-usuarios\" data-toc-modified-id=\"Cantidad-de-usuarios-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Cantidad de usuarios</a></div><div class=\"lev2 toc-item\"><a href=\"#Comportamiento-de-usuarios-segmentados-por-tipo-de-consumo\" data-toc-modified-id=\"Comportamiento-de-usuarios-segmentados-por-tipo-de-consumo-51\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Comportamiento de usuarios segmentados por tipo de consumo</a></div><div class=\"lev3 toc-item\"><a href=\"#Descripción-de-la-variables\" data-toc-modified-id=\"Descripción-de-la-variables-511\"><span class=\"toc-item-num\">5.1.1&nbsp;&nbsp;</span>Descripción de la variables</a></div><div class=\"lev3 toc-item\"><a href=\"#Segmentación-para-el-período-completo\" data-toc-modified-id=\"Segmentación-para-el-período-completo-512\"><span class=\"toc-item-num\">5.1.2&nbsp;&nbsp;</span>Segmentación para el período completo</a></div><div class=\"lev3 toc-item\"><a href=\"#Series-más-consultadas-por-grupo\" data-toc-modified-id=\"Series-más-consultadas-por-grupo-513\"><span class=\"toc-item-num\">5.1.3&nbsp;&nbsp;</span>Series más consultadas por grupo</a></div><div class=\"lev1 toc-item\"><a href=\"#Anexo\" data-toc-modified-id=\"Anexo-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Anexo</a></div><div class=\"lev2 toc-item\"><a href=\"#Fuentes-primarias\" data-toc-modified-id=\"Fuentes-primarias-61\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Fuentes primarias</a></div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"https://cdn.jupyter.org/notebook/5.1.0/style/style.min.css\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T18:12:54.592929Z",
     "start_time": "2019-08-09T18:12:54.585912Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import locale\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../../tools'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import gc\n",
    "\n",
    "import re\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot  as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from pylab import *\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import seaborn as sns\n",
    "from urllib.parse import parse_qs\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.preprocessing import maxabs_scale, minmax_scale, MinMaxScaler, StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import squarify\n",
    "\n",
    "import analytics_tools\n",
    "from IPython.core.display import display, HTML\n",
    "import dask.dataframe as dd\n",
    "\n",
    "locale.setlocale(locale.LC_ALL, '')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set()\n",
    "plt.rcParams['image.cmap'] = 'Accent'\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('precision',2)\n",
    "pd.set_option('display.float_format', lambda x: locale.format_string('%d', x, 1))\n",
    "\n",
    "import arrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T17:46:23.079464Z",
     "start_time": "2019-08-13T17:46:23.075657Z"
    }
   },
   "outputs": [],
   "source": [
    "# calcula los reportes para los últimos 365 días\n",
    "FROM_DATE = arrow.now().shift(years=-1).format(\"YYYY-MM-DD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T18:13:10.180464Z",
     "start_time": "2019-08-09T18:13:10.169997Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_html(content, tag='p'):\n",
    "    display(HTML( '<{0}>{1}</{0}>'.format(tag,content) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "# Uso de series en API Series de Tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:43:06.250088Z",
     "start_time": "2019-08-08T17:43:06.241837Z"
    },
    "variables": {
     "str_today": "2019-08-06 10:57:19.819226"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>Reporte creado el día: 2019-09-13 15:57:47.580665</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mssg = 'Reporte creado el día: {}'.format(str(pd.Timestamp.today())) \n",
    "\n",
    "display_html(mssg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Indice<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Uso-de-series-en-API-Series-de-Tiempo\" data-toc-modified-id=\"Uso-de-series-en-API-Series-de-Tiempo-0\"><span class=\"toc-item-num\">0&nbsp;&nbsp;</span>Uso de series en API Series de Tiempo</a></span></li><li><span><a href=\"#Resumen-ejecutivo\" data-toc-modified-id=\"Resumen-ejecutivo-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Resumen ejecutivo</a></span><ul class=\"toc-item\"><li><span><a href=\"#Origen-de-las-llamadas\" data-toc-modified-id=\"Origen-de-las-llamadas-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Origen de las llamadas</a></span></li><li><span><a href=\"#Sobre-las-fuentes-primarias\" data-toc-modified-id=\"Sobre-las-fuentes-primarias-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Sobre las fuentes primarias</a></span></li><li><span><a href=\"#Estado-de-las-series-publicadas\" data-toc-modified-id=\"Estado-de-las-series-publicadas-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Estado de las series publicadas</a></span><ul class=\"toc-item\"><li><span><a href=\"#Histogramas-de-las-series-diaras-actualizadas-y-desactualizadas\" data-toc-modified-id=\"Histogramas-de-las-series-diaras-actualizadas-y-desactualizadas-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Histogramas de las series diaras actualizadas y desactualizadas</a></span></li></ul></li><li><span><a href=\"#Llamadas-mensuales---Período-completo\" data-toc-modified-id=\"Llamadas-mensuales---Período-completo-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Llamadas mensuales - Período completo</a></span></li><li><span><a href=\"#Números-generales\" data-toc-modified-id=\"Números-generales-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Números generales</a></span><ul class=\"toc-item\"><li><span><a href=\"#Sobre-las-consultas\" data-toc-modified-id=\"Sobre-las-consultas-1.5.1\"><span class=\"toc-item-num\">1.5.1&nbsp;&nbsp;</span>Sobre las consultas</a></span></li><li><span><a href=\"#Sobre-los-usuarios\" data-toc-modified-id=\"Sobre-los-usuarios-1.5.2\"><span class=\"toc-item-num\">1.5.2&nbsp;&nbsp;</span>Sobre los usuarios</a></span></li><li><span><a href=\"#Series-populares\" data-toc-modified-id=\"Series-populares-1.5.3\"><span class=\"toc-item-num\">1.5.3&nbsp;&nbsp;</span>Series populares</a></span></li></ul></li></ul></li><li><span><a href=\"#Cantidad-de-llamadas\" data-toc-modified-id=\"Cantidad-de-llamadas-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Cantidad de llamadas</a></span><ul class=\"toc-item\"><li><span><a href=\"#Perfil-de-las-series\" data-toc-modified-id=\"Perfil-de-las-series-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Perfil de las series</a></span><ul class=\"toc-item\"><li><span><a href=\"#Perfil-de-series-diarias\" data-toc-modified-id=\"Perfil-de-series-diarias-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Perfil de series diarias</a></span></li></ul></li></ul></li><li><span><a href=\"#Cantidad-de-usuarios\" data-toc-modified-id=\"Cantidad-de-usuarios-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Cantidad de usuarios</a></span><ul class=\"toc-item\"><li><span><a href=\"#Comportamiento-de-usuarios-segmentados-por-tipo-de-consumo\" data-toc-modified-id=\"Comportamiento-de-usuarios-segmentados-por-tipo-de-consumo-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Comportamiento de usuarios segmentados por tipo de consumo</a></span><ul class=\"toc-item\"><li><span><a href=\"#Descripción-de-la-variables\" data-toc-modified-id=\"Descripción-de-la-variables-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Descripción de la variables</a></span></li><li><span><a href=\"#Segmentación-para-el-período-completo\" data-toc-modified-id=\"Segmentación-para-el-período-completo-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Segmentación para el período completo</a></span></li><li><span><a href=\"#Series-más-consultadas-por-grupo\" data-toc-modified-id=\"Series-más-consultadas-por-grupo-3.1.3\"><span class=\"toc-item-num\">3.1.3&nbsp;&nbsp;</span>Series más consultadas por grupo</a></span></li></ul></li></ul></li><li><span><a href=\"#Anexo\" data-toc-modified-id=\"Anexo-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Anexo</a></span><ul class=\"toc-item\"><li><span><a href=\"#Fuentes-primarias\" data-toc-modified-id=\"Fuentes-primarias-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Fuentes primarias</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:43:06.254998Z",
     "start_time": "2019-08-08T17:43:06.252527Z"
    },
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# Carga y normalización de analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:43:06.260214Z",
     "start_time": "2019-08-08T17:43:06.257242Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:43:06.266823Z",
     "start_time": "2019-08-08T17:43:06.262639Z"
    }
   },
   "outputs": [],
   "source": [
    "## Funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:43:06.340591Z",
     "start_time": "2019-08-08T17:43:06.268731Z"
    }
   },
   "outputs": [],
   "source": [
    "# formarters\n",
    "f_ar = lambda x: locale.format_string('%.2f', x, 1)\n",
    "d_ar = lambda x: locale.format_string('%d', x, 1)\n",
    "\n",
    "tz_arg = lambda x: pd.to_datetime(x).tz_localize('UTC').tz_convert(tz='America/Argentina/Buenos_Aires')\n",
    "\n",
    "TABLE_COUNTER = 0\n",
    "TABLE_TEMPLATE = \"\"\"\n",
    "<center><strong><small>{title}</small></strong></center>\n",
    "<center>{table}</center>\n",
    "<center><strong><small>Tabla {table_number}</small></strong></center>\n",
    "\"\"\"\n",
    "    \n",
    "def table_counter():\n",
    "    global TABLE_COUNTER\n",
    "    TABLE_COUNTER += 1\n",
    "    return TABLE_COUNTER\n",
    "\n",
    "def add_style_to_df(df, subset, color='black', font_weight=None):\n",
    "    render = df.style.set_properties(\n",
    "        subset= subset, \n",
    "        **{'font-weight': font_weight, 'color':color}).render().replace('\\n','')\n",
    "    return render\n",
    "\n",
    "def add_title(df_html, title):\n",
    "    str_table = TABLE_TEMPLATE.format(title=title, table=df_html, table_number=table_counter())\n",
    "    return str_table.replace('\\n','')\n",
    "\n",
    "def put_df_on_report(df, title, subset=None, color='black', font_weight='bold'):\n",
    "    if subset:\n",
    "        df_html = add_style_to_df(df, subset=subset,color=color, font_weight=font_weight)\n",
    "    else:\n",
    "        df_html = df.to_html().replace('\\n','')\n",
    "    return add_title(df_html, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:43:06.366532Z",
     "start_time": "2019-08-08T17:43:06.344963Z"
    }
   },
   "outputs": [],
   "source": [
    "midpoint = lambda x: (np.max(x)+ np.min(x))/2\n",
    "log_midpoint = lambda x: np.power(10,((np.log10(np.max(x))+np.log10(np.min(x)))/2))\n",
    "\n",
    "def read_files_to_df(directory, cols):\n",
    "    \"\"\"Lee CSVs de misma estructura en un directorio a un solo DataFrame.\"\"\"\n",
    "\n",
    "    file_pattern = os.path.join(directory, \"*.csv\")\n",
    "    dfs = [pd.read_csv(file, usecols = cols, encoding=\"utf8\", parse_dates=True)\n",
    "           for file in glob.glob(file_pattern)]\n",
    "        \n",
    "    return pd.concat(dfs, axis=0)\n",
    "\n",
    "def parse_ids(qs):\n",
    "    if pd.notna(qs):\n",
    "        if 'ids' in qs:\n",
    "            params = parse_qs(qs)\n",
    "            ids_values_str = params.get('ids',[''])[0]\n",
    "        else:\n",
    "            ids_values_str = qs\n",
    "\n",
    "        return [value.split(':')[0] for value in ids_values_str.split(',')]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def iter_series_ids(df):\n",
    "    for analytic_id, id_list in zip(df.id, df.ids):\n",
    "            if isinstance(id_list, list):\n",
    "                for serie_id in id_list:\n",
    "                    yield (analytic_id, serie_id)\n",
    "    \n",
    "def unfold_series_id(df):\n",
    "    list_ids = []\n",
    "    for analytic_id, serie_id in iter_series_ids(df):\n",
    "        list_ids.append([analytic_id, serie_id])\n",
    "        \n",
    "    df_ids = pd.DataFrame(list_ids, columns=['analytic_id','serie_id'])\n",
    "    df_ids.dropna(inplace=True)\n",
    "    \n",
    "    df_ids['analytic_id'] = df_ids['analytic_id'].astype(object)\n",
    "    \n",
    "    df_extended = df_ids.merge(df, left_on='analytic_id', right_on='id')\n",
    "    df_extended = df_extended.drop(columns=['analytic_id'])\n",
    "    \n",
    "    return df_extended\n",
    "\n",
    "def replace_and_drop_column(df, old_column, new_column):\n",
    "    df[new_column] = df[old_column]\n",
    "    new_df = df.drop(old_column, axis=1)\n",
    "    return new_df\n",
    "\n",
    "def add_totals(df):\n",
    "    df_to_append = pd.DataFrame(df.sum(numeric_only=True)).T\n",
    "    \n",
    "    df_appended = df.append(df_to_append)\n",
    "    \n",
    "    as_list = df_appended.index.tolist()\n",
    "    idx = as_list.index(0)\n",
    "    as_list[idx] = 'Total'\n",
    "    df_appended.index = as_list\n",
    "    \n",
    "    return df_appended\n",
    "\n",
    "def add_linear_regression(df, target_col, index_as_feature=True, feature_cols=''):\n",
    "    if index_as_feature:\n",
    "        X = df.index.values.reshape(-1, 1)\n",
    "    else:\n",
    "        n_r, n_c = df[feature_cols].shape\n",
    "        X = df[feature_cols].values.reshape(-1, n_c)\n",
    "        \n",
    "    y = df[target_col].values\n",
    "    \n",
    "    reg = LinearRegression()\n",
    "    reg.fit(X, y)\n",
    "    \n",
    "#     df['linear_regression'] = \n",
    "    return reg.predict(X)\n",
    "\n",
    "#\n",
    "def interpolate_by_days(df, column, date_col='' ,days=1, floor=0):\n",
    "    df['day_factor'] = pd.DatetimeIndex(df[date_col]).dayofyear % days\n",
    "    day_factor_unique = df.day_factor.unique()\n",
    "    list_df = []\n",
    "\n",
    "    call_col_inter = column + '_inter'\n",
    "    \n",
    "    for day_factor in day_factor_unique:\n",
    "#         for call_col in columns:\n",
    "        \n",
    "        filter_by_df = df.day_factor == day_factor\n",
    "        df_f = df[filter_by_df]\n",
    "        df_f[call_col_inter] = df_f[column].apply(lambda x: np.nan if x < floor else x)\n",
    "        df_f.loc[:,call_col_inter] = df_f[call_col_inter].interpolate(method='linear', limit_direction='both',inplace=False)\n",
    "        list_df.append(df_f)\n",
    "        del df_f\n",
    "\n",
    "    df_inter = pd.concat(list_df, sort=True)\n",
    "    \n",
    "    return df_inter[call_col_inter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:43:06.376046Z",
     "start_time": "2019-08-08T17:43:06.369744Z"
    }
   },
   "outputs": [],
   "source": [
    "# para retención de usr\n",
    "def get_week(d):\n",
    "    start = d - pd.Timedelta(days=d.weekday())\n",
    "    end = start + pd.Timedelta(days=6)\n",
    "    return end\n",
    "\n",
    "def cohort_period(df):\n",
    "    df['cohort_period'] = np.arange(len(df)) + 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:43:06.439927Z",
     "start_time": "2019-08-08T17:43:06.378556Z"
    }
   },
   "outputs": [],
   "source": [
    "# para clusterizar\n",
    "# recibe un unfolded\n",
    "def get_nunique_series_avg(df, frequency='W'):\n",
    "    \"\"\"Devuelve el promedio de cantidad de series únicas por la frencuencia indicada \"\"\"\n",
    "    df_list = []\n",
    "    \n",
    "    for frequency in 'DWM':\n",
    "        if frequency is 'D':\n",
    "            col = 'date'\n",
    "            frec_col = 'series_unicas_diarias'\n",
    "        elif frequency is 'W':\n",
    "            col = 'weekofyear'\n",
    "            frec_col = 'series_unicas_semanales'\n",
    "        elif frequency is 'M':\n",
    "            col = 'month'\n",
    "            frec_col = 'series_unicas_mensuales'\n",
    "        else:\n",
    "            return\n",
    "        \n",
    "        df_avg_series = df.groupby(['ip_address',col]).nunique()['serie_id'].reset_index()\n",
    "        \n",
    "#         n_series_unicas = df_avg_series.serie_id.count()\n",
    "        \n",
    "        df_avg_series = df_avg_series[['ip_address', 'serie_id']].groupby('ip_address').mean()\n",
    "        df_avg_series.rename({'serie_id':frec_col},axis=1, inplace=True) \n",
    "                \n",
    "        df_list.append(df_avg_series)\n",
    "\n",
    "    df_series_avg = pd.concat(df_list, axis=1).reset_index()\n",
    "    \n",
    "    ass = df[['month','ip_address', 'serie_id','indice_tiempo_frecuencia']].drop_duplicates()\n",
    "    id_unicos_por_ip_mes = ass.groupby(['ip_address','month']).nunique()['serie_id'].reset_index()\n",
    "    \n",
    "    serie_diaria = ass.indice_tiempo_frecuencia.str.contains('R/P1D')\n",
    "    id_diarios_unicos_por_ip_mes = ass[serie_diaria].groupby(['ip_address','month']).nunique()['serie_id'].reset_index()\n",
    "\n",
    "    ### ip - su - sud\n",
    "    ass = df[['ip_address', 'serie_id','indice_tiempo_frecuencia']].drop_duplicates()\n",
    "    id_unicos_por_ip_mes = ass.groupby('ip_address').nunique()['serie_id'].reset_index()\n",
    "    id_unicos_por_ip_mes.rename({'serie_id':'series_unicas'}, axis=1, inplace=True)\n",
    "    serie_diaria = ass.indice_tiempo_frecuencia.str.contains('R/P1D')\n",
    "    id_diarios_unicos_por_ip_mes = ass[serie_diaria].groupby('ip_address').nunique()['serie_id'].reset_index()\n",
    "    id_diarios_unicos_por_ip_mes.rename({'serie_id':'series_diarias_unicas'}, axis=1, inplace=True)\n",
    "\n",
    "    #n_id_diarios_unicos = id_diarios_unicos_por_ip_mes.groupby('ip_address').mean().reset_index()\n",
    "    asss = id_unicos_por_ip_mes.merge(id_diarios_unicos_por_ip_mes, on='ip_address', how='left').fillna(0)\n",
    "\n",
    "    ####\n",
    "    assss = asss\n",
    "\n",
    "    df_series_avg = df_series_avg.merge(assss, on='ip_address').fillna(0)\n",
    "\n",
    "    return df_series_avg\n",
    "\n",
    "\n",
    "# recibe un unfolded!\n",
    "def get_ips_calls_max(df, frequency='D'):\n",
    "    \"\"\"Devuelve el promedio diario de llamadas por IP \"\"\"\n",
    "    if frequency is 'W':\n",
    "        df_ncalls = df.groupby(['ip_address','weekofyear']).nunique()['id'].reset_index()\n",
    "    elif frequency is 'D':\n",
    "        df_ncalls = df.groupby(['ip_address','date']).nunique()['id'].reset_index()\n",
    "    else:   \n",
    "        return\n",
    "    \n",
    "    df_ncalls = df_ncalls.groupby(['ip_address']).max().reset_index()\n",
    "    df_ncalls.rename({'id':'max_calls'},axis=1, inplace=True)\n",
    "    df_ncalls.sort_values('max_calls', ascending=False, inplace=True)\n",
    "\n",
    "    return df_ncalls\n",
    "\n",
    "# recibe un unfolded!\n",
    "def get_ips_calls_count(df, frequency='D', scale='linear'):\n",
    "    \"\"\"Devuelve el promedio diario de llamadas por IP \"\"\"\n",
    "    if frequency is 'W':\n",
    "        df_ncalls = df.groupby(['ip_address','weekofyear']).nunique()['id'].reset_index()\n",
    "    elif frequency is 'D':\n",
    "        df_ncalls = df.groupby(['ip_address','date']).nunique()['id'].reset_index()\n",
    "    else:   \n",
    "        return\n",
    "    \n",
    "    df_ncalls = df_ncalls.groupby(['ip_address']).mean().reset_index()\n",
    "    df_ncalls.rename({'id':'actividad'},axis=1, inplace=True)\n",
    "    df_ncalls.sort_values('actividad', ascending=False, inplace=True)\n",
    "\n",
    "    if scale is 'log':\n",
    "        df_ncalls['actividad'] = df_ncalls.actividad.apply(np.log10)\n",
    "    \n",
    "    return df_ncalls\n",
    "\n",
    "# recibe un unfolded!\n",
    "def get_ips_persistency(df, frequency='W', scale='linear'):\n",
    "    \"\"\"Devuelve la proporción de semanas con actividad para cada IP\n",
    "    Args:\n",
    "        frequency: str. W o D\n",
    "    \"\"\"\n",
    "    if frequency is 'W':\n",
    "#         group_cols = ['year','month','ip_address']\n",
    "#         data_cols = group_cols + ['weekofyear']\n",
    "#         n_frec = df[['year','month','weekofyear']].groupby(['year','month']).nunique()[['weekofyear']].sum().values[0]\n",
    "#         df_persistency = df[data_cols].groupby(group_cols).nunique()[['weekofyear']]\n",
    "\n",
    "        group_cols = ['ip_address']\n",
    "        data_cols = group_cols + ['weekdate']\n",
    "        n_frec = df['weekdate'].nunique()\n",
    "        df_persistency = df[data_cols].groupby(group_cols).nunique()[['weekdate']]\n",
    "        \n",
    "#         print(n_frec)\n",
    "\n",
    "    elif frequency is 'D':\n",
    "        group_cols = ['ip_address']\n",
    "        data_cols = group_cols + ['date']\n",
    "\n",
    "        n_frec = df.date.nunique()\n",
    "\n",
    "        df_persistency = df[data_cols].groupby(group_cols).nunique()[['date']]\n",
    "    else:   \n",
    "        return\n",
    "    \n",
    "    df_persistency = df_persistency.unstack(level=0).unstack(level=0)\n",
    "    df_persistency = df_persistency.fillna(0).sum(1).reset_index()\n",
    "    df_persistency.rename({0:'persistencia'},axis=1, inplace=True)\n",
    "    df_persistency.sort_values('persistencia', ascending=False, inplace=True)\n",
    "    df_persistency['persistencia'] = df_persistency.persistencia.divide(n_frec/100)\n",
    "    \n",
    "    if scale is 'log':\n",
    "        df_persistency['persistencia'] = df_persistency.persistencia.apply(np.log10)\n",
    "\n",
    "    return df_persistency\n",
    "\n",
    "# recibe un unfolded!\n",
    "def get_ip_features(df, frequencies={'persistencia':'W','actividad':'D'}, scales={'persistencia':'linear','actividad':'log'}):\n",
    "    \n",
    "    df_ncalls = get_ips_calls_count(df, frequency=frequencies['actividad'], scale=scales['actividad'])\n",
    "    df_persistency = get_ips_persistency(df, frequency=frequencies['persistencia'], scale=scales['persistencia'])\n",
    "#     df_maxcalls = get_ips_calls_max(df)\n",
    "\n",
    "    df_ip_features = df_ncalls.merge(df_persistency, how='inner', on='ip_address')\n",
    "#     df_ip_features = df_ip_features.merge(df_maxcalls, how='inner', on='ip_address')\n",
    "    \n",
    "    return df_ip_features\n",
    "\n",
    "# \n",
    "def cluster_ips(df, n_kmeans=3, frequencies={'persistencia':'W','actividad':'D'}, scales={'persistencia':'linear','actividad':'log'},labels=None):\n",
    "    df_ip_features = get_ip_features(df, frequencies, scales)\n",
    "\n",
    "    X = df_ip_features[['actividad','persistencia']].values.reshape(-1, 2)\n",
    "    X_minmax = MinMaxScaler().fit_transform(X)\n",
    "#     X_minmax = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    clusters_id = KMeans(n_kmeans, random_state=0).fit_predict(X_minmax)\n",
    "\n",
    "    ips_clusterizados = df_ip_features.merge(pd.DataFrame(clusters_id), how='inner', left_index=True, right_index=True)\n",
    "    ips_clusterizados.rename({0:'cluster_id'}, axis=1, inplace=True)\n",
    "    ips_clusterizados['cluster_name'] = ips_clusterizados.cluster_id.apply(lambda x: labels[x])\n",
    "    return ips_clusterizados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:43:06.461183Z",
     "start_time": "2019-08-08T17:43:06.442043Z"
    }
   },
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "def make_cluster_plots(df_cluster, clusters, exclude_clusters_id=None):\n",
    "    \n",
    "    G = gridspec.GridSpec(4, 3)\n",
    "\n",
    "    plt.figure(figsize=[15,20])\n",
    "    \n",
    "    axes_1 = subplot(G[0:2, :])\n",
    "    plt.scatter(df_cluster['actividad'], df_cluster['persistencia'], c=df_cluster['color'], s=50,alpha=.7);\n",
    "    plt.title('Segmentación de usuarios, período completo')\n",
    "    plt.xlabel('actividad')\n",
    "    plt.ylabel('persistencia');\n",
    "\n",
    "    axes_3 = subplot(G[2:,:-1])\n",
    "    act_std = df_cluster.actividad.std()\n",
    "    pers_std = df_cluster.persistencia.std()\n",
    "    act_mean = df_cluster.actividad.mean()\n",
    "    pers_mean = df_cluster.persistencia.mean()\n",
    "\n",
    "    df_cluster['actividad_norm'] = minmax_scale(df_cluster.actividad, feature_range=(act_mean-2*act_std,act_mean+2*act_std))\n",
    "    df_cluster['persistencia_norm'] = minmax_scale(df_cluster.persistencia, feature_range=(pers_mean-2*pers_std,pers_mean+2*pers_std))\n",
    "    \n",
    "    df_cluster_profile = df_cluster[~df_cluster.cluster_id.isin(exclude_clusters_id)].groupby(['cluster_id','cluster_name','color']).agg({'ip_address': pd.Series.nunique,\n",
    "                                            'actividad_norm': pd.Series.mean,\n",
    "                                            'persistencia_norm': pd.Series.mean}).reset_index()\n",
    "\n",
    "    df_cluster_profile = df_cluster_profile.sort_values('ip_address', ascending=False)\n",
    "\n",
    "    with sns.axes_style('white'):\n",
    "    #     fig, ax = plt.subplots(figsize=(15,10))\n",
    "        axes_3.spines['bottom'].set_position('center')\n",
    "        axes_3.spines['left'].set_position('center')\n",
    "        axes_3.spines['bottom'].set_color('grey')\n",
    "        axes_3.spines['left'].set_color('grey')\n",
    "        axes_3.spines['right'].set_color('none')\n",
    "        axes_3.spines['top'].set_color('none')\n",
    "        axes_3.xaxis.set_label_coords(.95, 0.48)\n",
    "        axes_3.yaxis.set_label_coords(0.53, 0.08)\n",
    "        axes_3.set_alpha(.2)\n",
    "\n",
    "        a = np.abs(df_cluster_profile.actividad_norm)\n",
    "        p = np.abs(df_cluster_profile.persistencia_norm)\n",
    "        u = df_cluster_profile.ip_address\n",
    "        cluster_s = a * u / 100\n",
    "\n",
    "        df_cluster_profile.plot.scatter('actividad_norm','persistencia_norm', \n",
    "                                    c=df_cluster_profile.color.values,\n",
    "#                                     c=df_cluster_profile.index.values,\n",
    "                                    s=cluster_s, \n",
    "                                    cmap='Accent', \n",
    "                                    colorbar=False,\n",
    "                                    alpha=.55,\n",
    "                                    legend=True,\n",
    "                                    ax=axes_3);\n",
    "\n",
    "    for i, row in df_cluster_profile.iterrows():\n",
    "        txt = row.cluster_name\n",
    "        x = row.actividad_norm\n",
    "        y = row.persistencia_norm\n",
    "        axes_3.text(x, y, txt, horizontalalignment='center',verticalalignment='bottom')\n",
    "\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.xlabel('actividad');\n",
    "    plt.ylabel('persistencia');\n",
    "    plt.title('Variables normalizadas.');\n",
    "\n",
    "    df_cluster_agg = df_cluster.groupby(['cluster_id','cluster_name','color']).agg({'ip_address': pd.Series.nunique,\n",
    "                                                           'actividad': pd.Series.sum}).reset_index()\n",
    "    df_cluster_agg = df_cluster_agg.sort_values('cluster_id')\n",
    "\n",
    "    col = 'ip_address'\n",
    "    title = 'Usuarios'\n",
    "    axes = subplot(G[2,-1])\n",
    "\n",
    "\n",
    "    patches = df_cluster_agg[col].plot(kind='pie',autopct='%.1f',labels=None, fontsize=0, colors=df_cluster_agg.color.values, ax=axes)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('');\n",
    "    labels = ['{0} - {1:1.2f} %'.format(i,j) for i,j in zip(df_cluster_agg.cluster_name, df_cluster_agg[col].divide(df_cluster_agg[col].sum())*100)]\n",
    "    plt.legend(labels=labels, loc='best')\n",
    "\n",
    "    col = 'actividad'\n",
    "    title = 'Llamadas'\n",
    "    axes = subplot(G[3,-1])\n",
    "\n",
    "    patches = df_cluster_agg[col].plot(kind='pie',autopct='%.1f',labels=None, fontsize=0, colors=df_cluster_agg.color.values, ax=axes)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('');\n",
    "    labels = ['{0} - {1:1.2f} %'.format(i,j) for i,j in zip(df_cluster_agg.cluster_name, df_cluster_agg[col].divide(df_cluster_agg[col].sum())*100)]\n",
    "    plt.legend(labels=labels, loc='best')\n",
    "        \n",
    "#     plt.savefig('../graphs/graphs-{}-clusters.png'.format(clusters), dpi=64)\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:43:06.471986Z",
     "start_time": "2019-08-08T17:43:06.464108Z"
    }
   },
   "outputs": [],
   "source": [
    "# esto necesita un superrefactor\n",
    "\n",
    "def pie_plot_w_legend(pd_df=pd.DataFrame(),\n",
    "                      title='',\n",
    "                      colors=None,\n",
    "                      colors_in_df=True,\n",
    "                      ax=None):\n",
    "    \n",
    "#     colors = pd_df.iloc[:,1] if colors is None else colors\n",
    "    txts = pd_df.index\n",
    "    if colors is None and colors_in_df is False:\n",
    "#         if colors_in_df is True:\n",
    "        patches = pd_df.iloc[:,0].plot(kind='pie',autopct='%.2f',labels=['' for _ in pd_df.iloc[:,0]], fontsize=0, ax=ax, figsize=[15,15], startangle=45)\n",
    "    if colors_in_df is True:\n",
    "        colors = pd_df.iloc[:,1]\n",
    "        patches = pd_df.iloc[:,0].plot(kind='pie',autopct='%.2f',labels=['' for _ in pd_df.iloc[:,0]], fontsize=0, ax=ax, figsize=[15,15], colors=colors, startangle=45)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('');\n",
    "    labels = ['{1:0.2f} % - {0}'.format(i,j) for i,j in zip(txts, pd_df.iloc[:,0].divide(pd_df.iloc[:,0].sum())*100)]\n",
    "    plt.legend(labels=labels, loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:43:06.480908Z",
     "start_time": "2019-08-08T17:43:06.473672Z"
    }
   },
   "outputs": [],
   "source": [
    "## Datos analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:43:07.508884Z",
     "start_time": "2019-08-08T17:43:06.482810Z"
    }
   },
   "outputs": [],
   "source": [
    "# actualizo los analytics de ambas apis\n",
    "analytics_tools.update_analytics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:43:07.512872Z",
     "start_time": "2019-08-08T17:43:07.510384Z"
    }
   },
   "outputs": [],
   "source": [
    "# filtro las columnas no usadas. (al 2019-08-08 hay 240MB de diferencia)\n",
    "curated_fields = ['id', 'ip_address', 'host', 'uri', 'querystring', 'start_time',\n",
    "      'status_code', 'user_agent',\n",
    "       'x_source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:43:32.526028Z",
     "start_time": "2019-08-08T17:43:07.514264Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cargo csv's\n",
    "# df_analytics = read_files_to_df('/home/melik/sdt-analytics-download/')\n",
    "df_analytics = read_files_to_df(analytics_tools.DIR_DATA_SDT, curated_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:43:39.461127Z",
     "start_time": "2019-08-08T17:43:32.528678Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filtro analytics por valores de interés\n",
    "uri_serie = df_analytics.uri.str.contains('/series/api/series')\n",
    "status_ok = df_analytics.status_code == 200\n",
    "status_nan = df_analytics.status_code.isnull()\n",
    "\n",
    "df_analytics = df_analytics[(uri_serie) & (status_ok | status_nan)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:43:40.208358Z",
     "start_time": "2019-08-08T17:43:39.462540Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filtro analytics. Saco ip's de test, saco períodos sin datos\n",
    "\n",
    "# ips asociados al pico del 2018-12-21\n",
    "test_ips = ['190.16.55.43','190.210.119.109', '190.246.123.181']\n",
    "# ips asociados al pico del 2018-02-15\n",
    "test_ips.extend(['195.162.12.14','190.18.52.25'])\n",
    "\n",
    "exclude_test_ips = ~df_analytics.ip_address.isin(test_ips)\n",
    "df_analytics = df_analytics[exclude_test_ips]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:52:47.233485Z",
     "start_time": "2019-08-08T17:43:40.210136Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda/envs/analytics/lib/python3.7/site-packages/pandas/core/indexes/datetimelike.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, mapper, na_action)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-c083fbcc4048>\u001b[0m in \u001b[0;36mget_week\u001b[0;34m(d)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_week\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweekday\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Int64Index' object is not callable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-2f31706ee43a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdf_analytics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weekday'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatetimeIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_analytics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweekday\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdf_analytics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weekofyear'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatetimeIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_analytics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweekofyear\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdf_analytics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weekdate'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_analytics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"date\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_week\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mdf_analytics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weekdate_short'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_analytics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweekdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y-%m-%d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mdf_analytics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date_short'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatetimeIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_analytics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y-%m'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/analytics/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4037\u001b[0m             \u001b[0;31m# row-wise access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4038\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_extension_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4039\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4040\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4041\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/analytics/lib/python3.7/site-packages/pandas/core/arrays/datetimelike.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, mapper)\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     \u001b[0;31m# ------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/analytics/lib/python3.7/site-packages/pandas/core/indexes/datetimelike.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, mapper, na_action)\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_indexer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/analytics/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, mapper, na_action)\u001b[0m\n\u001b[1;32m   4879\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmulti\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4881\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4882\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4883\u001b[0m         \u001b[0mattributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_attributes_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/analytics/lib/python3.7/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_map_values\u001b[0;34m(self, mapper, na_action)\u001b[0m\n\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m         \u001b[0;31m# mapper is a function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1300\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-c083fbcc4048>\u001b[0m in \u001b[0;36mget_week\u001b[0;34m(d)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# para retención de usr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_week\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweekday\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslibs/timedeltas.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.timedeltas.Timedelta.__new__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslibs/timedeltas.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.timedeltas.convert_to_timedelta64\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslibs/timedeltas.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.timedeltas.delta_to_nanoseconds\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Cambio el tipo de dato de la columna 'timestamp' a datetime\n",
    "df_analytics['start_time_utc'] = pd.to_datetime(df_analytics['start_time'])\n",
    "\n",
    "# df_analytics['start_time'] = pd.DatetimeIndex(df_analytics['start_time']).tz_localize('UTC').tz_convert(tz='America/Argentina/Buenos_Aires')\n",
    "df_analytics['start_time'] = pd.DatetimeIndex(df_analytics['start_time']).tz_convert(tz='America/Argentina/Buenos_Aires')\n",
    "\n",
    "df_analytics[\"date\"] = pd.DatetimeIndex(df_analytics.start_time).normalize()\n",
    "df_analytics[\"hour\"] = pd.DatetimeIndex(df_analytics.start_time).hour\n",
    "df_analytics[\"month\"] = pd.DatetimeIndex(df_analytics.start_time).month\n",
    "df_analytics[\"year\"] = pd.DatetimeIndex(df_analytics.start_time).year\n",
    "df_analytics['weekday'] = pd.DatetimeIndex(df_analytics.start_time).weekday\n",
    "df_analytics['weekofyear'] = pd.DatetimeIndex(df_analytics.start_time).weekofyear\n",
    "df_analytics['weekdate'] = df_analytics[\"date\"].apply(get_week)\n",
    "df_analytics['weekdate_short'] = df_analytics.weekdate.dt.strftime(\"%Y-%m-%d\")\n",
    "df_analytics['date_short'] = pd.DatetimeIndex(df_analytics.date).strftime('%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:53:24.909679Z",
     "start_time": "2019-08-08T17:52:47.235158Z"
    }
   },
   "outputs": [],
   "source": [
    "# Separo las ids de la llamada\n",
    "df_analytics['ids'] = df_analytics.querystring.apply(parse_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:53:30.162523Z",
     "start_time": "2019-08-08T17:53:24.911773Z"
    }
   },
   "outputs": [],
   "source": [
    "# Borro duplicados\n",
    "df_analytics.drop_duplicates(subset='id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:53:30.166439Z",
     "start_time": "2019-08-08T17:53:30.164075Z"
    }
   },
   "outputs": [],
   "source": [
    "## Datos de la API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:53:32.568388Z",
     "start_time": "2019-08-08T17:53:30.173064Z"
    }
   },
   "outputs": [],
   "source": [
    "serie_metadata = 'https://apis.datos.gob.ar/series/api/dump/series-tiempo-metadatos.csv'\n",
    "curated_fields = ['catalogo_id', 'dataset_id', 'distribucion_id', 'serie_id',\n",
    "       'indice_tiempo_frecuencia',\n",
    "       'serie_descripcion', \n",
    "       'dataset_fuente',\n",
    "       'dataset_titulo', 'dataset_tema',\n",
    "       'serie_indice_final',\n",
    "       'serie_dias_no_cubiertos', 'serie_actualizada',\n",
    "       'serie_discontinuada',\n",
    "       'consultas_total']\n",
    "\n",
    "df_serie = pd.read_csv(serie_metadata, usecols=curated_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:53:32.573232Z",
     "start_time": "2019-08-08T17:53:32.570986Z"
    }
   },
   "outputs": [],
   "source": [
    "# r = df_serie.catalogo_id.shape\n",
    "# df_serie.catalogo_id.value_counts() / r * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:53:32.595329Z",
     "start_time": "2019-08-08T17:53:32.575222Z"
    }
   },
   "outputs": [],
   "source": [
    "# source_extendido= ['Banco Central de la República Argentina (BCRA)',\n",
    "#        'Bancos Centrales',\n",
    "#        'BCRA, MAE, Rofex',]\n",
    "\n",
    "sources = df_serie.dataset_fuente.unique()\n",
    "\n",
    "serie_source = df_serie.dataset_fuente.isin(sources)\n",
    "df_serie_source = df_serie[serie_source]\n",
    "df_serie_other_sources = df_serie[~serie_source]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:53:32.601951Z",
     "start_time": "2019-08-08T17:53:32.597631Z"
    }
   },
   "outputs": [],
   "source": [
    "serie_description = ['serie_id','serie_descripcion','dataset_fuente','dataset_tema','indice_tiempo_frecuencia']\n",
    "df_serie_short = df_serie[serie_description]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:53:32.616706Z",
     "start_time": "2019-08-08T17:53:32.603665Z"
    }
   },
   "outputs": [],
   "source": [
    "total_series_source = df_serie_source.serie_id.nunique()\n",
    "total_series = df_serie.serie_id.nunique()\n",
    "str_total_series_source = d_ar(total_series_source)\n",
    "\n",
    "percentage_source = total_series_source/total_series*100\n",
    "str_percentage_source = f_ar(percentage_source)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Resumen ejecutivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:54:00.293410Z",
     "start_time": "2019-08-08T17:53:32.618361Z"
    }
   },
   "outputs": [],
   "source": [
    "# genero df_unfolded para todo el período\n",
    "df_unfolded = unfold_series_id(df_analytics)\n",
    "# del df_analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:54:36.108504Z",
     "start_time": "2019-08-08T17:54:00.295405Z"
    }
   },
   "outputs": [],
   "source": [
    "# separo por series source, no source y total (df para gráfico histórico)\n",
    "dtype = dict(year=int)\n",
    "# df_unfolded = df_serie[['serie_id','dataset_fuente']].merge(df_unfolded.astype(dtype),how='inner', on='serie_id')\n",
    "# df_unfolded = df_serie.merge(df_unfolded.astype(dtype),how='inner', on='serie_id')\n",
    "df_unfolded = dd.merge(df_serie, df_unfolded,how='inner', on='serie_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:54:36.857453Z",
     "start_time": "2019-08-08T17:54:36.109974Z"
    }
   },
   "outputs": [],
   "source": [
    "source = df_unfolded.serie_id.isin(df_serie_source.serie_id)\n",
    "other_sources = df_unfolded.serie_id.isin(df_serie_other_sources.serie_id)\n",
    "\n",
    "df_unfolded['serie_fuente'] = 'other_sources'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:54:52.098402Z",
     "start_time": "2019-08-08T17:54:36.859180Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_unfolded.loc[source,'serie_fuente'] = 'source'\n",
    "df_unfolded.loc[source,'serie_fuente'] = df_unfolded.loc[source,'serie_fuente'].apply(lambda x: str(x)[6:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:54:53.357076Z",
     "start_time": "2019-08-08T17:54:52.100091Z"
    }
   },
   "outputs": [],
   "source": [
    "df_calls_full = df_unfolded[['serie_fuente','serie_id','date']].groupby(['date','serie_fuente']).count()\n",
    "df_calls_full = df_calls_full.unstack(level=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:54:53.364131Z",
     "start_time": "2019-08-08T17:54:53.358377Z"
    }
   },
   "outputs": [],
   "source": [
    "mi = df_calls_full.columns\n",
    "ind = pd.Index([e[0] +'_'+ e[1] for e in mi.tolist()])\n",
    "df_calls_full.columns = ind\n",
    "\n",
    "# df_calls_full.columns = pd.Series(df_calls_full.columns).apply(lambda x: x[9:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:54:53.371006Z",
     "start_time": "2019-08-08T17:54:53.367917Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_calls_full.rename({'serie_id_source':'consultas_source', 'serie_id_other_sources':'consultas_other_sources'}, axis=1, inplace=1)\n",
    "# df_calls_full['consultas_total'] = df_calls_full.consultas_source + df_calls_full.consultas_other_sources\n",
    "\n",
    "df_calls_full.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:54:58.542138Z",
     "start_time": "2019-08-08T17:54:53.373098Z"
    }
   },
   "outputs": [],
   "source": [
    "# filtro el último trimestre 2018\n",
    "## start_date = pd.to_datetime('2018-09-30')\n",
    "start_date = tz_arg('2018-10-01T03:00:00') \n",
    "exclude_before_date = df_unfolded.start_time > start_date\n",
    "\n",
    "# end_date = tz_arg('2018-12-31T04:00:00')\n",
    "# exclude_after_date = df_unfolded.start_time <= end_date\n",
    "\n",
    "# df_unfolded = df_unfolded[exclude_before_date & exclude_after_date]\n",
    "df_unfolded = df_unfolded[exclude_before_date]\n",
    "\n",
    "# genero df_unfolded's\n",
    "# comento esta linea porque mergeo df_serie completo en una celda más arriba\n",
    "# df_unfolded = df_serie.merge(df_unfolded.astype(dtype),how='inner', on='serie_id')\n",
    "\n",
    "source = df_unfolded.serie_id.isin(df_serie_source.serie_id)\n",
    "other_sources = df_unfolded.serie_id.isin(df_serie_other_sources.serie_id)\n",
    "\n",
    "df_source_unfolded = df_unfolded[source]\n",
    "df_other_sources_unfolded = df_unfolded[other_sources]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:55:00.097767Z",
     "start_time": "2019-08-08T17:54:58.543696Z"
    }
   },
   "outputs": [],
   "source": [
    "# hits\n",
    "df_hits = df_unfolded[['serie_id','id']].groupby('serie_id').count()\n",
    "df_hits = df_hits.sort_values('id', ascending=False).reset_index()\n",
    "df_hits = replace_and_drop_column(df_hits, 'id', 'consultas')\n",
    "\n",
    "df_hits = df_hits.merge(df_serie_short, how='inner', on='serie_id',sort=False)\n",
    "\n",
    "hits_source = df_hits.serie_id.isin(df_serie_source.serie_id)\n",
    "hits_other_sources = ~hits_source\n",
    "\n",
    "df_source_hits = df_hits[hits_source]\n",
    "df_other_sources_hits = df_hits[hits_other_sources]\n",
    "\n",
    "df_source_hits.rename({'indice_tiempo_frecuencia':'frecuencia'},axis=1, inplace=True)\n",
    "df_other_sources_hits.rename({'indice_tiempo_frecuencia':'frecuencia'},axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:55:08.457990Z",
     "start_time": "2019-08-08T17:55:00.099465Z"
    }
   },
   "outputs": [],
   "source": [
    "# ips\n",
    "df_ips = df_unfolded[['serie_id','ip_address']].groupby('serie_id').nunique()[['ip_address']]\n",
    "df_ips = df_ips.sort_values('ip_address', ascending=False).reset_index()\n",
    "df_ips = replace_and_drop_column(df_ips, 'ip_address', 'ip_cantidad')\n",
    "\n",
    "df_ips = df_ips.merge(df_serie_short, how='inner', on='serie_id',sort=False)\n",
    "\n",
    "ips_source = df_ips.serie_id.isin(df_serie_source.serie_id)\n",
    "ips_other_sources = ~ips_source\n",
    "\n",
    "df_source_ips = df_ips[ips_source]\n",
    "df_other_sources_ips = df_ips[ips_other_sources]\n",
    "\n",
    "df_source_ips.rename({'indice_tiempo_frecuencia':'frecuencia'},axis=1, inplace=True)\n",
    "df_other_sources_ips.rename({'indice_tiempo_frecuencia':'frecuencia'},axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:55:08.462589Z",
     "start_time": "2019-08-08T17:55:08.459580Z"
    }
   },
   "outputs": [],
   "source": [
    "# - AGREGAR LÍNEA MENSUAL CON LA CANTIDAD DE LLAMADAS POR MES (INTERPOLANDO LOS HUECOS), PARA TODO 2018\n",
    "# - CONSIDERAR SOLO EL ÚLTIMO TRIMESTRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:55:09.018527Z",
     "start_time": "2019-08-08T17:55:08.468709Z"
    }
   },
   "outputs": [],
   "source": [
    "# período \n",
    "analytics_dates = df_unfolded.date.sort_values().unique()\n",
    "analytics_start = str(analytics_dates[0]).split('T')[0][:10]\n",
    "analytics_end = str(analytics_dates[-1]).split('T')[0][:10]\n",
    "\n",
    "str_periodo = analytics_start + ' - ' + analytics_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:55:09.051486Z",
     "start_time": "2019-08-08T17:55:09.019809Z"
    }
   },
   "outputs": [],
   "source": [
    "df_1 = df_serie_source.groupby('indice_tiempo_frecuencia').count()[['serie_id']].rename({'serie_id':'series_source'}, axis=1)    \n",
    "df_2 = df_serie_other_sources.groupby('indice_tiempo_frecuencia').count()[['serie_id']].rename({'serie_id':'series_other_sources'}, axis=1)\n",
    "\n",
    "df_series_by_freq = pd.concat([df_1, df_2],axis=1, sort=False)\n",
    "df_series_by_freq.fillna(0, inplace=True)\n",
    "\n",
    "df_series_by_freq['proporcion_serie_source'] = 100*df_series_by_freq.series_source.divide(df_series_by_freq.series_source.sum())\n",
    "df_series_by_freq['proporcion_serie_other_sources'] = 100*df_series_by_freq.series_other_sources.divide(df_series_by_freq.series_other_sources.sum())\n",
    "\n",
    "df_series_by_freq = add_totals(df_series_by_freq)\n",
    "\n",
    "df_series_by_freq['proporcion_serie_source'] = df_series_by_freq['proporcion_serie_source'].apply(lambda x: locale.format_string('%.2f %%', x, 1))\n",
    "df_series_by_freq['proporcion_serie_other_sources'] = df_series_by_freq['proporcion_serie_other_sources'].apply(lambda x: locale.format_string('%.2f %%', x, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:55:09.091758Z",
     "start_time": "2019-08-08T17:55:09.054171Z"
    }
   },
   "outputs": [],
   "source": [
    "# cantidad total de hits a series del BCRA\n",
    "serie_source_total_hits = df_source_hits.consultas.sum()\n",
    "str_serie_source_total_hits = d_ar(serie_source_total_hits)\n",
    "\n",
    "# proporción de hits a series del BCRA sobre el total de hits\n",
    "source_hits_in_total = df_source_hits.consultas.sum()/df_hits.consultas.sum()*100\n",
    "str_source_hits_in_total = f_ar(source_hits_in_total)\n",
    "\n",
    "# cantidad de hits por serie del BCRA\n",
    "hits_top_5 = df_source_hits.head()\n",
    "hits_last_5 = df_source_hits.tail()\n",
    "\n",
    "percentage_top_5 = hits_top_5.consultas.sum()/serie_source_total_hits*100\n",
    "str_percentage_top_5 = f_ar(percentage_top_5)\n",
    "\n",
    "# cantidad de hits por frecuencia de serie BCRA vs no-BCRA\n",
    "df_1 = df_source_hits.groupby('frecuencia').sum()[['consultas']].rename({'consultas':'consultas_source'}, axis=1)\n",
    "df_2 = df_other_sources_hits.groupby('frecuencia').sum()[['consultas']].rename({'consultas':'consultas_other_sources'}, axis=1)\n",
    "df_hits_by_freq = pd.concat([df_1, df_2],axis=1, sort=False).fillna(0)\n",
    "\n",
    "df_hits_by_freq = add_totals(df_hits_by_freq)\n",
    "\n",
    "df_hits_by_freq['consultas_por_serie_source'] = (df_hits_by_freq.consultas_source / df_series_by_freq.series_source).fillna(0)\n",
    "df_hits_by_freq['consultas_por_serie_other_sources'] = (df_hits_by_freq.consultas_other_sources / df_series_by_freq.series_other_sources).fillna(0)\n",
    "\n",
    "df_hits_by_freq['consultas_por_serie_source'] = df_hits_by_freq['consultas_por_serie_source'].apply(lambda x: locale.format_string('%.2f', x, 1))\n",
    "df_hits_by_freq['consultas_por_serie_other_sources'] = df_hits_by_freq['consultas_por_serie_other_sources'].apply(lambda x: locale.format_string('%.2f', x, 1))\n",
    "\n",
    "str_calls_frec_diaria_source = d_ar(df_hits_by_freq.loc['R/P1D','consultas_source'])\n",
    "\n",
    "str_perc_frec_diaria_source = f_ar(df_hits_by_freq.loc['R/P1D','consultas_source']/df_hits_by_freq.loc[:,'consultas_source'].sum()*100)\n",
    "\n",
    "str_calls_by_frec_diaria_source = d_ar(df_hits_by_freq.loc['R/P1D','consultas_source']/df_series_by_freq.loc['R/P1D','series_source'].sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:55:09.124501Z",
     "start_time": "2019-08-08T17:55:09.094217Z"
    }
   },
   "outputs": [],
   "source": [
    "maxs = df_source_hits[['frecuencia','consultas']].groupby('frecuencia').max()\n",
    "\n",
    "maxs_source = maxs.merge(df_source_hits, how='inner', on=['consultas','frecuencia'])\n",
    "maxs_source = maxs_source.set_index('frecuencia')\n",
    "maxs_source = maxs_source.rename(index={'frecuencia':''})\n",
    "maxs_source.index.name = None\n",
    "maxs_source = maxs_source[['serie_id','consultas','serie_descripcion','dataset_tema']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:55:38.028156Z",
     "start_time": "2019-08-08T17:55:09.126558Z"
    }
   },
   "outputs": [],
   "source": [
    "series_call_by_week_avg = df_source_unfolded[['date']].resample('7D',on='date').count().mean().values[0]\n",
    "series_call_by_week_median = df_source_unfolded[['date']].resample('7D',on='date').count().median().values[0]\n",
    "\n",
    "df_weekly = pd.DataFrame([series_call_by_week_avg, series_call_by_week_median]).T\n",
    "df_weekly.rename({0:'promedio', 1: 'mediana'}, axis=1, inplace=True)\n",
    "\n",
    "as_list = df_weekly.index.tolist()\n",
    "idx = as_list.index(0)\n",
    "as_list[idx] = 'por semana'\n",
    "df_weekly.index = as_list\n",
    "\n",
    "\n",
    "series_calls_by_day_avg = df_source_unfolded[['serie_id','date']].groupby(['date']).count().mean().values[0]\n",
    "series_calls_by_day_median = df_source_unfolded[['serie_id','date']].groupby(['date']).count().median().values[0]\n",
    "\n",
    "str_series_calls_by_day_avg = f_ar(series_calls_by_day_avg)\n",
    "\n",
    "df_daily = pd.DataFrame([series_calls_by_day_avg, series_calls_by_day_median]).T\n",
    "df_daily.rename({0:'promedio', 1: 'mediana'}, axis=1, inplace=True)\n",
    "\n",
    "as_list = df_daily.index.tolist()\n",
    "idx = as_list.index(0)\n",
    "as_list[idx] = 'por día'\n",
    "df_daily.index = as_list\n",
    "\n",
    "df_avg_median = df_daily.append(df_weekly)\n",
    "df_avg_median = df_avg_median[['promedio']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:55:46.494983Z",
     "start_time": "2019-08-08T17:55:38.029419Z"
    }
   },
   "outputs": [],
   "source": [
    "# sobre los usuarios\n",
    "# cantidad de ips por serie del BCRA\n",
    "ips_top_5 = df_source_ips.head()\n",
    "ips_top_5.rename({'ip_cantidad':'usuarios'}, axis=1, inplace=True)\n",
    "ips_last_5 = df_source_ips.tail()\n",
    "\n",
    "# serie con más ips\n",
    "str_serie_top_1 = ips_top_5.iloc[0,2]\n",
    "str_serie_top_2 = ips_top_5.iloc[1,2]\n",
    "str_serie_top_3 = ips_top_5.iloc[2,2]\n",
    "\n",
    "# cantidad de ips para todas las series del BCRA\n",
    "total_ips = df_unfolded.ip_address.nunique();\n",
    "source_total_ips = df_source_unfolded.ip_address.nunique();\n",
    "other_sources_total_ips = df_other_sources_unfolded.ip_address.nunique();\n",
    "str_source_total_ips = d_ar(source_total_ips)\n",
    "\n",
    "# proporción de ips para las series del BCRA sobre el total\n",
    "source_ips_in_total = source_total_ips/total_ips*100\n",
    "str_source_ips_in_total = f_ar(source_ips_in_total)\n",
    "\n",
    "# cantidad de ips por frecuencia de serie BCRA vs no-BCRA\n",
    "df_source_ip_by_frec = df_source_unfolded[['ip_address','indice_tiempo_frecuencia']].groupby('indice_tiempo_frecuencia').nunique()[['ip_address']].rename({'ip_address':'source_ip_cantidad'}, axis=1)\n",
    "df_other_sources_ip_by_frec = df_other_sources_unfolded[['ip_address','indice_tiempo_frecuencia']].groupby('indice_tiempo_frecuencia').nunique()[['ip_address']].rename({'ip_address':'other_sources_ip_cantidad'}, axis=1)\n",
    "df_ips_by_freq = pd.concat([df_source_ip_by_frec, df_other_sources_ip_by_frec],axis=1, sort=False).fillna(0)\n",
    "\n",
    "# df_ips_by_freq = add_totals(df_ips_by_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:58:28.197764Z",
     "start_time": "2019-08-08T17:55:46.496480Z"
    }
   },
   "outputs": [],
   "source": [
    "df_fuentes_features = pd.DataFrame(index=df_serie_source.dataset_fuente.unique())\n",
    "\n",
    "fuente_grouper = df_source_unfolded.groupby('dataset_fuente')\n",
    "\n",
    "# df_fuentes_features['series_por_fuente'] = (df_serie_source.dataset_fuente.value_counts() / df_serie_source.serie_id.nunique() * 100)\n",
    "df_fuentes_features['series'] = df_serie_source.dataset_fuente.value_counts()\n",
    "df_fuentes_features['usuarios'] = fuente_grouper.nunique()['ip_address']\n",
    "df_fuentes_features['consultas'] = fuente_grouper.count()['serie_id']\n",
    "\n",
    "df_fuentes_features['usuarios_por_serie'] = df_fuentes_features.usuarios.divide(df_fuentes_features.series)\n",
    "df_fuentes_features['consultas_por_serie'] = df_fuentes_features.consultas.divide(df_fuentes_features.series)\n",
    "\n",
    "df_fuentes_features = df_fuentes_features.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:58:28.610643Z",
     "start_time": "2019-08-08T17:58:28.199243Z"
    }
   },
   "outputs": [],
   "source": [
    "for c in ['series','consultas']:\n",
    "    new_c = '{}_porcentaje'.format(c)\n",
    "    df_fuentes_features[new_c] = df_fuentes_features[c]/df_fuentes_features[c].sum()*100\n",
    "    \n",
    "df_fuentes_features['usuarios_porcentaje'] = df_fuentes_features['usuarios'].divide(df_source_unfolded.ip_address.nunique())*100        \n",
    "\n",
    "for c in df_fuentes_features.columns[-3:]:\n",
    "        df_fuentes_features[c] = df_fuentes_features[c].apply(lambda x: locale.format_string('%.2f %%', x, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T18:01:50.474558Z",
     "start_time": "2019-08-08T18:01:50.466303Z"
    },
    "variables": {
     "str_percentage_source": "<p><strong>NameError</strong>: name &#39;str_percentage_source&#39; is not defined</p>\n",
     "str_series_calls_by_day_avg": "<p><strong>NameError</strong>: name &#39;str_series_calls_by_day_avg&#39; is not defined</p>\n",
     "str_source_total_ips": "<p><strong>NameError</strong>: name &#39;str_source_total_ips&#39; is not defined</p>\n",
     "str_total_series_source": "<p><strong>NameError</strong>: name &#39;str_total_series_source&#39; is not defined</p>\n"
    }
   },
   "outputs": [],
   "source": [
    "mssg = \"\"\"\n",
    "- Reciben un promedio de {} consultas por día. <br>\n",
    "- Fueron consultadas por {} usuarios identificados.\"\"\".format(str_series_calls_by_day_avg, str_source_total_ips)\n",
    "\n",
    "display_html(mssg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Origen de las llamadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los componentes de origen (campo *x_source*) identificados al momento son dos: El portal del Ministerio de Hacienda y el explorador de Series de Tiempo.\n",
    "\n",
    "Hasta ahora solo se identificó a los usuarios (campo *user_agent*) que utilizan spreadsheets de google para consumir el servicio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T18:02:07.216674Z",
     "start_time": "2019-08-08T18:02:07.212376Z"
    }
   },
   "outputs": [],
   "source": [
    "# min hacienda\n",
    "str_qss = \"?ids=143.3_ICE_SER_VM_2004_A_34&limit=1000&sort=desc\t?ids=45.2_ECTDT_0_T_33&limit=1000&sort=desc\t?ids=74.3_ISC_0_M_19&limit=1000&sort=desc\t?ids=131.1_FET_0_0_12&limit=1000&sort=desc\t?ids=89.2_TS_INTE_PM_0_D_16&limit=1000&sort=desc\t?ids=145.3_INGNACUAL_DICI_M_38&limit=1000&sort=desc\t?ids=169.1_MALVAL_0_0_6&limit=1000&sort=desc\t?ids=172.3_TL_RECA_IA_M_0_0_24&limit=1000&sort=desc\t?ids=38.3_CEM_1994_M_7&limit=1000&sort=desc\t?ids=154.2_COBAOBA_S_0_0_7&limit=1000&sort=desc\"\n",
    "str_qss = str_qss.replace('\\t','')\n",
    "qss = str.split(str_qss, '?')\n",
    "qss = qss[1:]\n",
    "\n",
    "# len(qss)\n",
    "# qss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:31:30.308751Z",
     "start_time": "2019-08-08T15:31:26.705148Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, qs in enumerate(qss):\n",
    "    filter_qs = df_analytics.querystring == qs\n",
    "    df_qs = df_analytics[filter_qs][['date','hour','ip_address']].drop_duplicates()\n",
    "    \n",
    "    if i == 0:\n",
    "        df_qss = df_qs\n",
    "    else:\n",
    "        df_qss = df_qss.merge(df_qs, how='inner')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:31:30.531134Z",
     "start_time": "2019-08-08T15:31:30.310335Z"
    }
   },
   "outputs": [],
   "source": [
    "qss_r, qss_c = df_qss.shape\n",
    "\n",
    "x_source = df_analytics.x_source.value_counts(dropna=False).to_frame()\n",
    "\n",
    "x_source_nan = x_source.loc[ np.nan,'x_source']\n",
    "\n",
    "x_source.loc['otros',:] = x_source_nan - qss_r * len(qss)\n",
    "x_source.loc['explorador series de tiempo',:] = x_source.loc[['series-tiempo-explorer', 'ts-components'],:].sum()\n",
    "x_source.loc['portal ministerio de hacienda',:] = qss_r * len(qss)\n",
    "x_source = x_source.iloc[-3:,:] \n",
    "\n",
    "x_source['color'] = ['C9','C2','C1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:31:30.995598Z",
     "start_time": "2019-08-08T15:31:30.532901Z"
    }
   },
   "outputs": [],
   "source": [
    "user_agent = df_analytics.user_agent.value_counts(dropna=False).to_frame()\n",
    "user_is_gl = user_agent.index.str.contains('Google') & user_agent.index.str.contains('pps-')\n",
    "\n",
    "gl_sum = user_agent[user_is_gl].sum()\n",
    "not_gl_sum = user_agent[~user_is_gl].sum()\n",
    "\n",
    "user_agent = pd.DataFrame([gl_sum, not_gl_sum], index=['google-spreadsheet-app','otros'])\n",
    "\n",
    "# user_agent['color'] = pd.Series(['C2','C9'],name='color')\n",
    "user_agent['color'] = ['C0','C9']\n",
    "\n",
    "# x_source = df_analytics.x_source.value_counts(dropna=False).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:31:31.364381Z",
     "start_time": "2019-08-08T15:31:30.996871Z"
    }
   },
   "outputs": [],
   "source": [
    "# fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "G = gridspec.GridSpec(1,2)\n",
    "\n",
    "ax1 = subplot(G[0, 0])\n",
    "pie_plot_w_legend(pd_df= x_source, title = 'Porcentaje de componente de origen', ax=ax1, colors_in_df=True)\n",
    "\n",
    "ax2 = subplot(G[0, 1])\n",
    "pie_plot_w_legend(pd_df= user_agent, title = 'Porcentaje de agentes de usuarios', ax=ax2, colors_in_df=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobre las fuentes primarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T18:52:27.235868Z",
     "start_time": "2019-08-09T18:52:27.225890Z"
    }
   },
   "outputs": [],
   "source": [
    "n_fuentes = df_serie_source.dataset_fuente.nunique()\n",
    "\n",
    "mssg = \"\"\"El catálogo de la SSPM incluye {} fuentes primarias. <br>\n",
    "En un primer análisis destacan los siguientes puntos: <br><br>\n",
    "1. el INDEC concentra el 75% de la actividad, y presenta más del 40% de las series del catálogo.<br>\n",
    "2. el Ministerio de Hacienda, con más del 30% de las series del catálogo, apenas supera el 10% de usuarios del total.<br>\n",
    "3. por el contrario, el BCRA con menos del 10% de las series, atrae a casi la totalidad de usuarios y ocupa un 15% de la actividad.<br><br>\n",
    "En el anexo se presenta la tabla completa de fuentes primarias del catálogo. <br>\n",
    "\"\"\".format(n_fuentes)\n",
    "\n",
    "display_html(mssg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:31:31.783043Z",
     "start_time": "2019-08-08T15:31:31.365843Z"
    }
   },
   "outputs": [],
   "source": [
    "# pd.set_option('display.float_format', lambda x: locale.format_string('%d', x, 1))\n",
    "pd.set_option('display.float_format', lambda x: locale.format_string('%.2f', x, 1))\n",
    "\n",
    "aux = df_fuentes_features.sort_values('usuarios', ascending=False)[['usuarios','consultas','series']]\n",
    "\n",
    "aux['usuarios'] = aux['usuarios']/df_source_unfolded.ip_address.nunique()*100\n",
    "\n",
    "for c in ['consultas','series']:\n",
    "    aux[c] = aux[c]/aux[c].sum()*100\n",
    "        \n",
    "usr_floor = aux.usuarios > 10\n",
    "calls_floor = aux.consultas > 14\n",
    "series_floor = aux.series > 4\n",
    "\n",
    "calls_pie = aux[calls_floor].consultas\n",
    "calls_pie = calls_pie.append(pd.Series(100-aux[calls_floor].consultas.sum(), index=['Otros']))\n",
    "\n",
    "series_pie = aux[series_floor].series\n",
    "series_pie = series_pie.append(pd.Series(100-aux[series_floor].series.sum(), index=['Otros']))\n",
    "\n",
    "usr_barh = aux[usr_floor].usuarios\n",
    "\n",
    "# colores!\n",
    "source_color = ['C{}'.format(i) for i in np.arange(len(usr_barh))]\n",
    "source_color = pd.Series(source_color, index=usr_barh.index)\n",
    "source_color = source_color.append(pd.Series('C9', index=['Otros']))\n",
    "\n",
    "calls_pie = pd.concat([calls_pie, source_color], axis=1, join='inner')\n",
    "series_pie = pd.concat([series_pie, source_color], axis=1, join='inner')\n",
    "usr_barh = pd.concat([usr_barh, source_color], axis=1, join='inner')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:31:32.351148Z",
     "start_time": "2019-08-08T15:31:31.784702Z"
    }
   },
   "outputs": [],
   "source": [
    "G = gridspec.GridSpec(2,2)\n",
    "plt.figure(figsize=[15,30])\n",
    "\n",
    "axes_1 = subplot(G[0, :])\n",
    "usr_barh.usuarios.plot(kind='barh', title='Porcentaje de usuarios del catálogo - Fuentes primarias más relevantes', \n",
    "              figsize=[10,6], ax=axes_1, color=usr_barh.iloc[:,1]);\n",
    "plt.grid(axis='y')\n",
    "\n",
    "axes_2 = subplot(G[1, 0])\n",
    "pie_plot_w_legend(pd_df= series_pie, title = 'Porcentaje de cantidad de series sobre el catálogo', ax=axes_2)\n",
    "\n",
    "axes_3 = subplot(G[1, 1])\n",
    "pie_plot_w_legend(pd_df = calls_pie, title = 'Porcentaje de cantidad de consultas recibidas', ax=axes_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estado de las series publicadas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T18:53:53.085598Z",
     "start_time": "2019-08-09T18:53:53.080609Z"
    }
   },
   "outputs": [],
   "source": [
    "mssg = \"\"\"Se definen para las series las siguientes características: <br><br>\n",
    "- actualizada: serie que incluye datos de los últimos 14 días (únicamente series diarias) o últimos 2 períodos.<br>\n",
    "- desactualizada: serie que incluye datos entre los últimos 15 y 90 días (únicamente series diarias), o entre los últimos 3 y 4 períodos.<br>\n",
    "- discontinuada: serie que incluye datos con una antigüedad mayor a 90 días (únicamente series diarias), o 5 períodos.<br>\"\"\"\n",
    "\n",
    "display_html(mssg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:31:32.361466Z",
     "start_time": "2019-08-08T15:31:32.353141Z"
    }
   },
   "outputs": [],
   "source": [
    "# flow\n",
    "# - calcular los días sin data.\n",
    "# - hacer una fn para cada categoría (alcanza sólo con actualizada y desact.)\n",
    "#     - quizás tenga que hacer un dict, con las frecuencias y los días de cada período. \n",
    "#     - y construir desp un dict con lo que aplica para cada categoría.\n",
    "    \n",
    "d_freq_days ={'R/P1D':1,\n",
    "              'R/P1M':30,\n",
    "              'R/P1Y':360,\n",
    "              'R/P3M':90,\n",
    "              'R/P6M':180}\n",
    "\n",
    "MAX_DAYS_DAILY_SERIE_UPDATED = 14\n",
    "MAX_PERIODS_SERIE_UPDATED = 2\n",
    "\n",
    "MAX_DAYS_DAILY_SERIE_NOT_UPDATED = 90\n",
    "MAX_PERIODS_SERIE_NOT_UPDATED = 4\n",
    "\n",
    "def serie_is_actualizada(df):\n",
    "#     print(df)\n",
    "    if df.indice_tiempo_frecuencia == 'R/P1D':\n",
    "        if df.serie_dias_sin_datos <= MAX_DAYS_DAILY_SERIE_UPDATED:\n",
    "            df['serie_actualizada_usr'] = True\n",
    "        else:\n",
    "            df['serie_actualizada_usr'] = False\n",
    "    else:\n",
    "        if df.serie_dias_sin_datos / d_freq_days[df.indice_tiempo_frecuencia] <= MAX_PERIODS_SERIE_UPDATED:\n",
    "            df['serie_actualizada_usr'] = True\n",
    "        else:\n",
    "            df['serie_actualizada_usr'] = False\n",
    "    return df\n",
    "            \n",
    "def serie_is_desactualizada(df):\n",
    "    if df.indice_tiempo_frecuencia == 'R/P1D':\n",
    "        if (df.serie_dias_sin_datos > MAX_DAYS_DAILY_SERIE_UPDATED) and (df.serie_dias_sin_datos <= MAX_DAYS_DAILY_SERIE_NOT_UPDATED):\n",
    "            df['serie_desactualizada_usr'] = True\n",
    "        else:\n",
    "            df['serie_desactualizada_usr'] = False\n",
    "    else:\n",
    "        dias_sin_datos = df.serie_dias_sin_datos / d_freq_days[df.indice_tiempo_frecuencia]\n",
    "        if (dias_sin_datos > MAX_PERIODS_SERIE_UPDATED) and dias_sin_datos <= MAX_PERIODS_SERIE_NOT_UPDATED:\n",
    "            df['serie_desactualizada_usr'] = True\n",
    "        else:\n",
    "            df['serie_desactualizada_usr'] = False\n",
    "    return df\n",
    "\n",
    "def serie_is_discontinuada(df):\n",
    "    if df.indice_tiempo_frecuencia == 'R/P1D':\n",
    "        if df.serie_dias_sin_datos > MAX_DAYS_DAILY_SERIE_NOT_UPDATED:\n",
    "            df['serie_discontinuada_usr'] = True\n",
    "        else:\n",
    "            df['serie_discontinuada_usr'] = False\n",
    "    else:\n",
    "        dias_sin_datos = df.serie_dias_sin_datos / d_freq_days[df.indice_tiempo_frecuencia]\n",
    "        if dias_sin_datos > MAX_PERIODS_SERIE_NOT_UPDATED:\n",
    "            df['serie_discontinuada_usr'] = True\n",
    "        else:\n",
    "            df['serie_discontinuada_usr'] = False\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:31:32.795020Z",
     "start_time": "2019-08-08T15:31:32.363004Z"
    }
   },
   "outputs": [],
   "source": [
    "lambda_days_wo_data = lambda x: (pd.Timestamp.today() - pd.Timestamp(x)).days\n",
    "df_serie_source['serie_dias_sin_datos'] = df_serie_source.serie_indice_final.apply(lambda_days_wo_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:32:14.567368Z",
     "start_time": "2019-08-08T15:31:32.796668Z"
    }
   },
   "outputs": [],
   "source": [
    "df_serie_source = df_serie_source.apply(serie_is_actualizada, axis=1)\n",
    "df_serie_source = df_serie_source.apply(serie_is_desactualizada, axis=1)\n",
    "df_serie_source = df_serie_source.apply(serie_is_discontinuada, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:32:15.444763Z",
     "start_time": "2019-08-08T15:32:14.569036Z"
    }
   },
   "outputs": [],
   "source": [
    "# actualizadas\n",
    "series_actualizadas_per = df_serie_source.serie_actualizada.value_counts()/df_serie_source.serie_actualizada.count()*100\n",
    "\n",
    "series_is_no_actualizada = df_serie_source.serie_actualizada == False\n",
    "series_no_actualizadas = df_serie_source[series_is_no_actualizada].serie_id\n",
    "\n",
    "# discontinuadas\n",
    "DAYS_WO_DATA_MAX = 365*3\n",
    "lambda_is_discontinued = lambda x: True if (pd.Timestamp.today() - pd.Timestamp(x)).days > DAYS_WO_DATA_MAX else False\n",
    "lambda_days_wo_data = lambda x: (pd.Timestamp.today() - pd.Timestamp(x)).days\n",
    "\n",
    "df_serie_source['serie_dias_sin_datos'] = df_serie_source.serie_indice_final.apply(lambda_days_wo_data)\n",
    "df_serie_source['serie_discontinuada_adhoc'] = df_serie_source.serie_indice_final.apply(lambda_is_discontinued)\n",
    "\n",
    "series_discontinuadas_bool = series_is_no_actualizada & df_serie_source.serie_discontinuada_adhoc\n",
    "\n",
    "# series_discontinuadas_per = df_serie_source.serie_discontinuada_adhoc.value_counts()/df_serie_source.serie_discontinuada_adhoc.count()*100\n",
    "series_discontinuadas_per = series_discontinuadas_bool.value_counts()/series_discontinuadas_bool.count()*100\n",
    "\n",
    "series_is_no_discontinuada = df_serie_source.serie_discontinuada_adhoc == False\n",
    "\n",
    "# desactualizadas\n",
    "series_desactualizadas = df_serie_source[series_is_no_actualizada & series_is_no_discontinuada].serie_id\n",
    "df_serie_source['serie_desactualizada'] = df_serie_source.serie_id.isin(series_desactualizadas)\n",
    "series_desactualizadas_per = df_serie_source['serie_desactualizada'].value_counts()/df_serie_source.serie_id.count()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:32:15.456082Z",
     "start_time": "2019-08-08T15:32:15.446174Z"
    }
   },
   "outputs": [],
   "source": [
    "series_actualizadas_per = df_serie_source.serie_actualizada_usr.value_counts()/df_serie_source.serie_actualizada_usr.count()*100\n",
    "series_desactualizadas_per = df_serie_source.serie_desactualizada_usr.value_counts()/df_serie_source.serie_desactualizada_usr.count()*100\n",
    "series_discontinuadas_per = df_serie_source.serie_discontinuada_usr.value_counts()/df_serie_source.serie_discontinuada_usr.count()*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:32:15.698000Z",
     "start_time": "2019-08-08T15:32:15.457416Z"
    }
   },
   "outputs": [],
   "source": [
    "df_series_estado = pd.DataFrame([series_discontinuadas_per, \n",
    "                                 series_desactualizadas_per, \n",
    "                                 series_actualizadas_per], \n",
    "                                index=['series discontinuadas',\n",
    "                                       'series desactualizadas',\n",
    "                                       'series actualizadas'])\n",
    "\n",
    "# df_series_estado.sort_values(False, ascending=False, inplace=True)\n",
    "df_series_estado.plot(y=True, kind='barh',figsize=[14,6], title='Estado de las series', color='C0', legend=False)\n",
    "\n",
    "t_y = [0, 1, 2]\n",
    "t_x = [48, 35, 20]\n",
    "l = ['1','2','3']\n",
    "for i, record in enumerate(df_series_estado.iterrows()):\n",
    "    ix, row = record\n",
    "    plt.text(row[1]/2, i, '{:.2f} %'.format(row[1]),\n",
    "            bbox=dict(facecolor='w', edgecolor='w', alpha=.65))\n",
    "    \n",
    "plt.xlabel('porcentaje');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogramas de las series diaras actualizadas y desactualizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:32:15.702409Z",
     "start_time": "2019-08-08T15:32:15.699973Z"
    }
   },
   "outputs": [],
   "source": [
    "# para pasar a beni\n",
    "# serie_es_diaria = df_serie_source.indice_tiempo_frecuencia == 'R/P1D'\n",
    "# serie_esta_actualizada = df_serie_source.serie_actualizada == True\n",
    "\n",
    "# df_serie_source[serie_es_diaria & serie_esta_actualizada][['serie_id','serie_descripcion','serie_indice_final','serie_dias_no_cubiertos']];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:32:16.141795Z",
     "start_time": "2019-08-08T15:32:15.704225Z"
    }
   },
   "outputs": [],
   "source": [
    "# serie_actualizada = df_serie_source.serie_actualizada == True\n",
    "serie_actualizada = df_serie_source.serie_dias_sin_datos < 15\n",
    "serie_actualizada = df_serie_source.serie_actualizada_usr\n",
    "\n",
    "# serie_desactualizada = (df_serie_source.serie_actualizada == False) & (df_serie_source.serie_discontinuada_adhoc == False)\n",
    "# serie_desactualizada = (~serie_actualizada) & (df_serie_source.serie_discontinuada_adhoc == False)\n",
    "serie_desactualizada = df_serie_source.serie_desactualizada_usr\n",
    "\n",
    "\n",
    "serie_es_diaria = df_serie_source.indice_tiempo_frecuencia == 'R/P1D'\n",
    "\n",
    "# fig, (ax1, ax2) = plt.subplots(2,1,sharex=True)\n",
    "fig, (ax1, ax2) = plt.subplots(2,1)\n",
    "df_serie_source[serie_actualizada & serie_es_diaria].serie_dias_sin_datos.hist(bins=20, figsize=[12,10], ax=ax1);\n",
    "ax1.set_title('Histogramas de series diarias actualizadas y desactualizadas');\n",
    "ax1.set_xlabel('días sin datos')\n",
    "ax1.set_ylabel('cantidad de series actualizadas');\n",
    "\n",
    "df_serie_source[serie_desactualizada & serie_es_diaria].serie_dias_sin_datos.hist(bins=20, figsize=[12,10], ax=ax2);\n",
    "# plt.title('Series diarias desactualizadas');\n",
    "ax2.set_xlabel('días sin datos')\n",
    "ax2.set_ylabel('cantidad de series desactualizadas');\n",
    "\n",
    "ax1.grid(axis='x')\n",
    "ax2.grid(axis='x')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llamadas mensuales - Período completo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:32:16.319741Z",
     "start_time": "2019-08-08T15:32:16.143768Z"
    }
   },
   "outputs": [],
   "source": [
    "df_calls_full_date = df_calls_full.resample('D', on='date').sum().reset_index().copy()\n",
    "\n",
    "filter_calls = df_calls_full_date.columns.str.contains('s_source') | df_calls_full_date.columns.str.contains('tota')\n",
    "calls_columns = df_calls_full_date.columns[filter_calls]\n",
    "\n",
    "\n",
    "# df_calls_full_date['consultas_source_inter'] = interpolate_by_days(df_calls_full_date, # df_calls_by_day_count\n",
    "#                                             column= 'consultas_source', \n",
    "#                                             date_col='date',\n",
    "#                                             days=42,\n",
    "#                                             floor=750);\n",
    "df_calls_full_date['consultas_source_inter'] = interpolate_by_days(df_calls_full_date, # df_calls_by_day_count\n",
    "                                            column= 'serie_id_source', \n",
    "                                            date_col='date',\n",
    "                                            days=42,\n",
    "                                            floor=750);\n",
    "\n",
    "\n",
    "# df_calls_full_date['consultas_total_inter'] = interpolate_by_days(df_calls_full_date,\n",
    "#                                             column= 'serie_id_total', \n",
    "#                                             date_col='date',\n",
    "#                                             days=42,\n",
    "#                                             floor=8000);\n",
    "\n",
    "# df_calls_full_date.loc[:,'propocion_inter'] = df_calls_full_date.consultas_source_inter.divide(df_calls_full_date.consultas_total_inter)*100\n",
    "\n",
    "df_calls_full_month = df_calls_full_date.resample('M', on='date').agg({'consultas_source_inter': pd.Series.sum}).copy()\n",
    "#                                                        'propocion_inter': pd.Series.mean}).copy()# sum()\n",
    "df_calls_full_month.reset_index(inplace=True)\n",
    "\n",
    "# # saco 2019\n",
    "# df_calls_full_tx = df_calls_full_month.iloc[:-2,:].copy()\n",
    "df_calls_full_tx = df_calls_full_month\n",
    "\n",
    "# acorto date\n",
    "df_calls_full_tx.loc[:,'date'] = df_calls_full_month.date.apply(pd.datetime.strftime,args=['%Y-%m'])\n",
    "df_calls_full_tx.reset_index(inplace=True)\n",
    "\n",
    "df_calls_full_tx = df_calls_full_tx.iloc[:-1,:]\n",
    "\n",
    "# df_calls_full_tx['tendencia'] = add_linear_regression(df_calls_full_tx, 'consultas_source_inter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:32:16.818556Z",
     "start_time": "2019-08-08T15:32:16.320979Z"
    }
   },
   "outputs": [],
   "source": [
    "# n_row, n_col = df_calls_full_tx.shape\n",
    "# scatter_color = np.array([sns.xkcd_rgb[\"windows blue\"] for _ in range(n_row)])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "\n",
    "# df_calls_full_tx.plot.scatter(x='index', y='consultas_source_inter',ax=ax,legend=True, s=99, c=scatter_color);\n",
    "df_calls_full_tx.plot.bar(x='date',\n",
    "                          y='consultas_source_inter',\n",
    "                          ax=ax,\n",
    "                          legend=False, \n",
    "                          color=sns.xkcd_palette([\"windows blue\"]),\n",
    "                          stacked=True);\n",
    "# df_calls_full_tx.plot.line(y='tendencia',ax=ax,legend=True, lw=2, alpha=.4, style='--');\n",
    "\n",
    "# ax.set_ylim(0,80000)\n",
    "ax.set_ylabel('cantidad de consultas BCRA')\n",
    "plt.grid(axis='x')\n",
    "\n",
    "# ax2 = ax.twinx()\n",
    "# df_calls_full_tx.plot.scatter(x='index', y='propocion_inter',ax=ax2,legend=True, s=99, c='green');\n",
    "# df_calls_full_tx.plot.line(x='date',y='propocion_inter',ax=ax2,legend=True, lw=3, c='green');\n",
    "\n",
    "# ax2.set_ylabel('cantidad de consultas totales')\n",
    "# ax2.set_ylim(0,800000)\n",
    "\n",
    "plt.xticks(df_calls_full_tx.index, df_calls_full_tx.date, rotation=45)\n",
    "# plt.legend(fontsize=15)\n",
    "\n",
    "plt.title('Consultas mensuales a series del catálogo SSPM')\n",
    "plt.ylabel('cantidad de consultas')\n",
    "plt.xlabel('fecha');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Números generales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La mayor cantidad de series del catálogo SSPM en la API de Series de Tiempo son de frecuencia anual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "variables": {
     "str_calls_by_frec_diaria_source": {},
     "str_perc_frec_diaria_source": {},
     "str_periodo": {}
    }
   },
   "outputs": [],
   "source": [
    "mssg = \"\"\"Las series diarias son consultadas mucho más intensamemnte que las series de otras frecuencias.\n",
    "\n",
    "En el período considerado ({}), las series diarias recibieron el {}% de las consultas a series del catálogo SSPM. Esto hace que en promedio, cada serie diaria haya sido consultada {} veces.\"\"\".format(str_periodo, str_perc_frec_diaria_source, str_calls_by_frec_diaria_source)\n",
    "\n",
    "display_html(mssg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En forma similar a como ocurre con la cantidad de llamadas a series de distintas frecuencias, vemos que las series diarias y mensuales tienen una base de usuarios mucho más amplia que las otras frecuencias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:32:17.302616Z",
     "start_time": "2019-08-08T15:32:16.850003Z"
    }
   },
   "outputs": [],
   "source": [
    "df_series_by_freq.rename({'series_source':'series','proporcion_serie_source':'proporcion'}, axis=1, inplace=True)\n",
    "\n",
    "df_hits_by_freq.rename({'consultas_source':'consultas','consultas_por_serie_source':'consultas_por_serie'},\n",
    "                      axis=1, inplace=True)\n",
    "\n",
    "df_ips_by_freq.columns = ['usuarios', 'other_sources_ip_cantidad']\n",
    "df_ips_by_freq = add_totals(df_ips_by_freq)\n",
    "df_ips_by_freq.loc['Total','usuarios'] = df_source_unfolded.ip_address.nunique()\n",
    "\n",
    "\n",
    "df_1 = df_series_by_freq[['series','proporcion']]\n",
    "df_2 = df_hits_by_freq[['consultas','consultas_por_serie']]\n",
    "df_3 = df_ips_by_freq[['usuarios']]\n",
    "\n",
    "df_series_by_frec_merge = pd.concat([df_1, df_2, df_3], axis=1, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:32:17.313304Z",
     "start_time": "2019-08-08T15:32:17.304761Z"
    }
   },
   "outputs": [],
   "source": [
    "str_df_series_by_freq = put_df_on_report(df_series_by_frec_merge,title='Cantidad, consultas y usuarios de series disponibles en la API, por frecuencia')\n",
    "\n",
    "display(HTML(str_df_series_by_freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre las consultas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las cinco series del catálogo SSPM más consultadas, reúnen el 25,37% de consultas totales realizadas: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:32:17.339224Z",
     "start_time": "2019-08-08T15:32:17.330431Z"
    }
   },
   "outputs": [],
   "source": [
    "str_hits_top_5 = put_df_on_report(hits_top_5,title='Series más consultadas')\n",
    "\n",
    "display(HTML(str_hits_top_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre los usuarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El 99,40% de los usuarios de la API Series de Tiempo consultan series del catálogo SSPM.<br>\n",
    "En el período 2018-10-01 - 2019-08-07, la cantidad de usuarios fue de 83.107"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando vemos la popularidad de las series por cantidad de usuarios, en vez de por cantidad de llamadas, la lista de las series más populares cambia, mostrando que el grueso de los usuarios consulta la serie *Índice de Tipo de Cambio Real Multilateral*, seguidas de *Instrumentos del BCRA. Tasa de Política Monetaria.* y *Saldo comercial. En millones de dólares.*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:32:17.399351Z",
     "start_time": "2019-08-08T15:32:17.392743Z"
    }
   },
   "outputs": [],
   "source": [
    "str_ips_top_5 = put_df_on_report(ips_top_5,title='Series con más usuarios')\n",
    "\n",
    "display(HTML(str_ips_top_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:32:17.408617Z",
     "start_time": "2019-08-08T15:32:17.406414Z"
    },
    "variables": {
     "bcra_total_ips": "<p><strong>NameError</strong>: name &#39;bcra_total_ips&#39; is not defined</p>\n",
     "df_ips_by_freq": "<p><strong>NameError</strong>: name &#39;df_ips_by_freq&#39; is not defined</p>\n",
     "ips_last_5": "<p><strong>NameError</strong>: name &#39;ips_last_5&#39; is not defined</p>\n",
     "ips_top_5": "<p><strong>NameError</strong>: name &#39;ips_top_5&#39; is not defined</p>\n",
     "str_bcra_ips_in_total": "<p><strong>NameError</strong>: name &#39;str_bcra_ips_in_total&#39; is not defined</p>\n"
    }
   },
   "outputs": [],
   "source": [
    "# df_ips_by_freq.loc['Total',:] = [source_total_ips, other_sources_total_ips]\n",
    "\n",
    "# df_ips_by_freq['source_ip_cantidad'] = df_ips_by_freq['source_ip_cantidad'].apply(lambda x: locale.format_string('%d', x, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series populares "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente gráfico muestra la cantidad de usuarios por cantidad de llamadas, para cada serie del catálogo SSPM. <br>\n",
    "\n",
    "Se trazan líneas auxiliares en la media de cada eje, y se sombrea el área que contiene a las series más consultadas y con mayor cantidad de usuarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:32:17.457019Z",
     "start_time": "2019-08-08T15:32:17.410504Z"
    }
   },
   "outputs": [],
   "source": [
    "df_hits_ips = df_source_hits[['serie_id','consultas']].merge(df_source_ips, how='inner' ,on='serie_id')\n",
    "frec_series = pd.Series(df_hits_ips.frecuencia.unique())\n",
    "\n",
    "df_hits_ips['frec_id'] = df_hits_ips[['serie_id','frecuencia']].groupby(['frecuencia']).ngroup()\n",
    "df_hits_ips.rename({'ip_cantidad':'usuarios'}, axis=1,inplace=True)\n",
    "\n",
    "# df_hits_ips['rank'] = df_hits_ips.consultas.apply(np.log10) * df_hits_ips.ip_cantidad.apply(np.log10)\n",
    "\n",
    "for c in ['consultas', 'usuarios']:\n",
    "    c_norm = c + '_norm'\n",
    "    df_hits_ips[c_norm] = (df_hits_ips[c] - df_hits_ips[c].mean()) / (df_hits_ips[c].max() - df_hits_ips[c].min())\n",
    "\n",
    "X = df_hits_ips.consultas.values.reshape(-1, 1)\n",
    "Y = df_hits_ips.usuarios.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:32:17.467602Z",
     "start_time": "2019-08-08T15:32:17.459260Z"
    }
   },
   "outputs": [],
   "source": [
    "n_series = 20\n",
    "\n",
    "# df_hits_ips['rank'] = df_hits_ips.consultas_norm + df_hits_ips.usuarios_norm\n",
    "\n",
    "# top_usr_ix = df_hits_ips.nlargest(n_series, 'usuarios_norm').index.to_series()\n",
    "# top_act_ix = df_hits_ips.nlargest(n_series, 'consultas_norm').index.to_series()\n",
    "\n",
    "top_usr_ix = df_hits_ips['usuarios'] > 900\n",
    "top_act_ix = df_hits_ips['consultas'] > 30000\n",
    "\n",
    "# top_ix = top_act_ix[top_act_ix.isin(top_usr_ix)]\n",
    "top_ix = top_act_ix & top_usr_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:32:17.480940Z",
     "start_time": "2019-08-08T15:32:17.469513Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_hits_ips.loc[:,'rank'] = df_hits_ips.index.to_series().isin(top_ix)\n",
    "df_hits_ips.loc[:,'rank'] = top_ix\n",
    "\n",
    "\n",
    "# df_hits_ips.loc[:,'rank'] = True if (df_hits_ips.index.to_series() in top_usr_ix) and (df_hits_ips.index.to_series() in top_act_ix) else False\n",
    "\n",
    "top_rank = df_hits_ips[df_hits_ips['rank']==True].sort_values('usuarios',ascending=False) #.head(n_series)\n",
    "# top_rank = df_hits_ips.nlargest(n_series, 'rank', keep='all')\n",
    "# top_rank = df_hits_ips.nsmallest(n_series, 'rank', keep='all')\n",
    "top_rank_short = top_rank.iloc[:,[0,3,5,4,1,2]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:32:19.306925Z",
     "start_time": "2019-08-08T15:32:17.482762Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "fourth_quad = (X >= log_midpoint(X)) & (Y <= log_midpoint(Y))\n",
    "fourth_quad = fourth_quad.squeeze()\n",
    "\n",
    "second_subquad = (X >= midpoint(X)) & (Y <= midpoint(Y)) & (Y >= log_midpoint(Y))\n",
    "second_subquad = second_subquad.squeeze()\n",
    "\n",
    "forth_subquad = (X <= midpoint(X)) & (Y >= midpoint(Y)) & (X >= log_midpoint(X))\n",
    "forth_subquad = forth_subquad.squeeze()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "\n",
    "\n",
    "for frec in df_hits_ips.frecuencia.unique():\n",
    "    is_frec = df_hits_ips.frecuencia.str.contains(frec)\n",
    "    if is_frec.sum() > 0:\n",
    "        X_frec = df_hits_ips[is_frec].consultas\n",
    "        y_frec = df_hits_ips[is_frec].usuarios\n",
    "\n",
    "        plt.scatter(X_frec, y_frec, s=80,  label=frec, alpha=.5);\n",
    "\n",
    "out_X = X[second_subquad | forth_subquad].squeeze()\n",
    "out_y = Y[second_subquad | forth_subquad].squeeze()\n",
    "\n",
    "out_toggler = np.array([np.where(out_X==n)[0][0]%2 for n in out_X])\n",
    "out_toggler[np.where(out_toggler==0)[0]] = -1\n",
    "out_toggler = -1*out_toggler\n",
    "\n",
    "plt.legend(fontsize=15, title='Frecuencias')\n",
    "\n",
    "labels = df_hits_ips[second_subquad | forth_subquad].serie_descripcion.values\n",
    "\n",
    "plt.axvline(x=np.mean(X),ymin=0, ymax=1, linestyle='--', color='grey', alpha=0.5)\n",
    "plt.axhline(y=np.mean(Y),xmin=0, xmax=1, linestyle='--', color='grey', alpha=0.5)\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.title('Cantidad de ips por cantidad de consultas para cada serie. Escala logarítmica')\n",
    "plt.xlabel('Cantidad de llamadas (log)')\n",
    "plt.ylabel('Cantidad de ips (log)');\n",
    "\n",
    "rect = patches.FancyBboxPatch((top_rank.consultas.min(),top_rank.usuarios.min()), width=top_rank.consultas.max(), height=top_rank.usuarios.max()\n",
    "                         , color='grey', linestyle='--', alpha=0.15)\n",
    "\n",
    "ax.add_patch(rect);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:32:19.315834Z",
     "start_time": "2019-08-08T15:32:19.308473Z"
    }
   },
   "outputs": [],
   "source": [
    "str_top_rank = put_df_on_report(top_rank_short.sort_values('usuarios', ascending=False), 'Las series más populares')\n",
    "\n",
    "display(HTML(str_top_rank))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cantidad de llamadas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perfil de las series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Promedio por día y por semana de las consultas a las series del catálogo SSPM:\n",
    "<div>\n",
    "<style scoped>\n",
    "    .dataframe tbody tr th:only-of-type {\n",
    "        vertical-align: middle;\n",
    "    }\n",
    "\n",
    "    .dataframe tbody tr th {\n",
    "        vertical-align: top;\n",
    "    }\n",
    "\n",
    "    .dataframe thead th {\n",
    "        text-align: right;\n",
    "    }\n",
    "</style>\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>promedio</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>por día</th>\n",
    "      <td>18.449,90</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>por semana</th>\n",
    "      <td>127.099,33</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:32:19.758872Z",
     "start_time": "2019-08-08T15:32:19.333108Z"
    }
   },
   "outputs": [],
   "source": [
    "days_name = ['lunes','martes','miércoles','jueves','viernes','sábado','domingo']\n",
    "\n",
    "source_calls_by_day_count = df_source_unfolded[['serie_id','date']].groupby(['date']).count()\n",
    "source_calls_by_weekday = source_calls_by_day_count.groupby(pd.DatetimeIndex(source_calls_by_day_count.index).weekday)\n",
    "\n",
    "source_calls_by_weekday_avg = source_calls_by_weekday.mean().reset_index()\n",
    "source_calls_by_weekday_avg = source_calls_by_weekday_avg.rename(index=str, columns={\"serie_id\":\"source_calls\"})\n",
    "\n",
    "other_sources_calls_by_day_count = df_other_sources_unfolded[['serie_id','date']].groupby(['date']).count()\n",
    "other_sources_calls_by_weekday = other_sources_calls_by_day_count.groupby(pd.DatetimeIndex(other_sources_calls_by_day_count.index).weekday)\n",
    "\n",
    "other_sources_calls_by_weekday_avg = other_sources_calls_by_weekday.mean().reset_index()\n",
    "other_sources_calls_by_weekday_avg = other_sources_calls_by_weekday_avg.rename(index=str, columns={\"serie_id\":\"other_sources_calls\"})\n",
    "\n",
    "calls_by_weekday_avg = source_calls_by_weekday_avg.merge(other_sources_calls_by_weekday_avg,on='date')\n",
    "\n",
    "\n",
    "calls_by_weekday_avg['day'] = days_name\n",
    "calls_by_weekday_avg.set_index('day',inplace=True)\n",
    "\n",
    "c_max = calls_by_weekday_avg['source_calls'].max()\n",
    "c_min = calls_by_weekday_avg['source_calls'].mean()\n",
    "\n",
    "c_delta = (c_max - c_min)/c_max*100\n",
    "str_c_delta = f_ar(c_delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perfil de series diarias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se presenta el promedio de llamadas por hora y por día de la semana para las series diarias.\n",
    "\n",
    "Se observa que los valores son mayores para las horas de oficina, por lo que se entiende que detrás del consumo de las series hay un factor de trabajo humano ascociado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:32:20.342295Z",
     "start_time": "2019-08-08T15:32:19.760142Z"
    }
   },
   "outputs": [],
   "source": [
    "source_calls_date_hr_count = df_source_unfolded[['serie_id','date', 'hour']].groupby(['date','hour']).count().reset_index()\n",
    "source_calls_day_hour_mean = source_calls_date_hr_count.groupby([pd.DatetimeIndex(source_calls_date_hr_count.date).weekday,'hour']).mean()\n",
    "source_calls_day_hour_mean = source_calls_day_hour_mean.unstack(level=-2)\n",
    "source_calls_day_hour_mean.sort_index(ascending=False, inplace=True)\n",
    "\n",
    "source_calls_day_hour_mean = source_calls_day_hour_mean.loc[21:7,:]\n",
    "\n",
    "# source_calls_day_hour_mean.rename({0:''}, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:32:21.051450Z",
     "start_time": "2019-08-08T15:32:20.343462Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[12,8])\n",
    "\n",
    "sns.heatmap(source_calls_day_hour_mean, cmap=sns.color_palette(\"Blues\", 20), annot=True, fmt='.2f', annot_kws={'size': 14}, cbar=False);\n",
    "\n",
    "plt.xticks(ticks=source_calls_day_hour_mean.columns.levels[1]+.5 ,labels=days_name)\n",
    "plt.yticks(rotation='horizontal')\n",
    "plt.ylabel('horas')\n",
    "plt.xlabel('días de la semana')\n",
    "plt.title('Series diarias BCRA - Promedio de llamadas por hora y día de la semana.');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cantidad de usuarios "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se describe el comportamiento de los usuarios que consumen series del catálogo SSPM en la API Series de Tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comportamiento de usuarios segmentados por tipo de consumo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T11:57:18.050694Z",
     "start_time": "2019-01-21T11:57:18.042312Z"
    },
    "hide_input": true
   },
   "source": [
    "Para entender el comportamiento de los usuarios, se consideran las siguientes variables:\n",
    "   - _persistencia_: proporción de semanas en las que el usuario utilizó el servicio en el período considerado, y\n",
    "   - _actividad_: promedio diario de consultas realizadas en el período considerado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descripción de la variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:32:21.056384Z",
     "start_time": "2019-08-08T15:32:21.052798Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: locale.format_string('%.2f', x, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:34:28.027067Z",
     "start_time": "2019-08-08T15:32:21.058283Z"
    }
   },
   "outputs": [],
   "source": [
    "df_features = get_ip_features(df_source_unfolded, frequencies={'persistencia':'W','actividad':'D'}, scales={'persistencia':'linear','actividad':'linear'})\n",
    "features_described = df_features.describe().loc[['mean','std','min','max'],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:34:28.032167Z",
     "start_time": "2019-08-08T15:34:28.028551Z"
    }
   },
   "outputs": [],
   "source": [
    "str_features_described = put_df_on_report(features_described,'Medidias de las variables')\n",
    "\n",
    "display(HTML(str_features_described))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:34:28.697638Z",
     "start_time": "2019-08-08T15:34:28.042288Z"
    }
   },
   "outputs": [],
   "source": [
    "# get_ips_persistency(df_source_unfolded).hist(bins=50, figsize=[15,8])\n",
    "df_features[['persistencia']].hist(bins=50, figsize=[15,8])\n",
    "plt.yscale('log')\n",
    "plt.title('Persistencia - Histograma')\n",
    "plt.ylabel('Cantidad de ips (log)')\n",
    "plt.xlabel('Proporción de semanas con actividad');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:34:29.308175Z",
     "start_time": "2019-08-08T15:34:28.699161Z"
    }
   },
   "outputs": [],
   "source": [
    "df_features[['actividad']].hist(bins=50, figsize=[15,8])\n",
    "plt.yscale('log')\n",
    "plt.title('Actividad - Histograma')\n",
    "plt.ylabel('Cantidad de ips (log)')\n",
    "plt.xlabel('Promedio diario de llamadas');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_features\n",
    "del df_analytics\n",
    "del df_unfolded\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentación para el período completo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se identifican seis grupos de usuarios:\n",
    "1. Ocasionales: Presenta niveles muy bajos de actividad y persistencia. Es el grupo de usuarios más extenso.\n",
    "1. Exploratorios 1: Tiene niveles bajos de actividad y persistencia.\n",
    "1. Exploratorios 2: Aún con actividad baja, es significativamente más persistentes que Exploratorios 1.\n",
    "1. Regulares: Alcanza niveles medios de actividad y persistencia.\n",
    "1. Persistentes: Tiene nivel medio de actividad y nivel alto persistencia.\n",
    "1. Intensivos: Presenta alto nivel de actividad. Es el grupo con mayor dispersión.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los siguientes gráficos se muestran:\n",
    "- Para cada usuario, la relación entre su _persistencia_ y su _actividad_, distinguiendo cuatro grupos según esas variables.\n",
    "- La media de los cuatro grupos con las variables normalizadas en los ejes. El tamaño del grupo en el gráfico, refiere a la cantidad de usuarios de cada uno. Por cuestiones gráficas, se excluye el grupo *intensivo*.\n",
    "- Las proporciones de usuarios y llamadas que toma cada grupo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:36:45.071929Z",
     "start_time": "2019-08-08T15:34:29.310285Z"
    }
   },
   "outputs": [],
   "source": [
    "group_qty = 6\n",
    "\n",
    "group_names = ['ocasionales', 'persistentes', 'exploratorios 2', 'regulares', 'exploratorios 1', 'intensivos']\n",
    "group_colors = ['C{}'.format(i%10) for i in np.arange(len(group_names))]\n",
    "\n",
    "df_cluster = cluster_ips(df_source_unfolded, n_kmeans=group_qty,\n",
    "                         frequencies={'persistencia':'W','actividad':'D'},\n",
    "                         scales={'persistencia':'linear','actividad':'linear'},\n",
    "                         labels= group_names);\n",
    "\n",
    "df_group_colors = pd.DataFrame(group_colors, index=group_names, columns=['color'])\n",
    "\n",
    "df_cluster = df_cluster.merge(df_group_colors, left_on='cluster_name', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:45:02.892527Z",
     "start_time": "2019-08-08T15:44:58.240367Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "make_cluster_plots(df_cluster, clusters=group_qty, exclude_clusters_id=[group_qty-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:45:26.133553Z",
     "start_time": "2019-08-08T15:45:02.894118Z"
    }
   },
   "outputs": [],
   "source": [
    "df_unfolded_clusters = df_source_unfolded[['ip_address','serie_id','indice_tiempo_frecuencia']].merge(df_cluster, on='ip_address')\n",
    "\n",
    "serie_diaria = df_unfolded_clusters.indice_tiempo_frecuencia.str.contains('R/P1D')\n",
    "\n",
    "# df_id_unicas_por_cluster = df_unfolded_clusters.groupby('cluster_id').nunique()['serie_id'].reset_index()\n",
    "# df_id_diarias_unicas_por_cluster = df_unfolded_clusters[serie_diaria].groupby('cluster_id').nunique()['serie_id'].reset_index()\n",
    "\n",
    "df_id_unicas_por_cluster = df_unfolded_clusters.groupby('cluster_id').nunique()['serie_id'].reset_index()\n",
    "# df_id_unicas_por_cluster = df_id_unicas_por_cluster.groupby\n",
    "\n",
    "df_id_diarias_unicas_por_cluster = df_unfolded_clusters[serie_diaria].groupby('cluster_id').nunique()['serie_id'].reset_index()\n",
    "\n",
    "addd = df_id_unicas_por_cluster.merge(df_id_diarias_unicas_por_cluster, on='cluster_id')\n",
    "addd['proporcion_series_diarias'] = addd.serie_id_y / addd.serie_id_x * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:51:38.428073Z",
     "start_time": "2019-08-08T15:45:26.135600Z"
    }
   },
   "outputs": [],
   "source": [
    "df_series_avg = get_nunique_series_avg(df_source_unfolded, frequency='D')\n",
    "df_cluster = df_cluster.merge(df_series_avg, how='inner', on='ip_address')\n",
    "\n",
    "df_cluster_profile = df_cluster.groupby(['cluster_id','cluster_name']).agg({'ip_address': pd.Series.nunique,\n",
    "                                        'actividad': pd.Series.mean,\n",
    "                                        'persistencia': pd.Series.mean,\n",
    "#                                         'series_unicas_diarias': pd.Series.mean,\n",
    "#                                         'series_unicas_semanales': pd.Series.mean,\n",
    "                                        'series_unicas_mensuales': pd.Series.mean,\n",
    "#                                         'series_unicas': pd.Series.sum,\n",
    "#                                         'series_diarias_unicas': pd.Series.sum\n",
    "                                                                           }).reset_index()\n",
    "\n",
    "# df_cluster_profile['proporcion_series_diarias'] = df_cluster_profile.series_diarias_unicas / df_cluster_profile.series_unicas * 100\n",
    "# df_cluster_profile.drop(columns=['series_unicas','series_diarias_unicas'], inplace=True)\n",
    "\n",
    "df_cluster_profile = df_cluster_profile.sort_values('actividad',ascending=False).reset_index(drop=True)\n",
    "df_cluster_profile.rename({'ip_address':'usuarios', 'cluster_name':'grupo'}, axis=1, inplace=True)\n",
    "\n",
    "for c in df_cluster_profile.columns[2:].values:\n",
    "    df_cluster_profile[c] = df_cluster_profile[c].apply(lambda x: locale.format_string('%.2f', x, 1))\n",
    "\n",
    "df_cluster_profile = df_cluster_profile.merge(addd[['cluster_id','proporcion_series_diarias']], on='cluster_id')\n",
    "# df_cluster_profile = df_cluster_profile.merge(addd, on='cluster_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el perfil de los grupos se incluye el promedio mensual de la cantidad de series distintas que consultan (*series_unicas_mensuales*) y la proporción de series diarias en el total de series únicas consultadas (*proporcion_series_diaras*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:51:38.438794Z",
     "start_time": "2019-08-08T15:51:38.430083Z"
    }
   },
   "outputs": [],
   "source": [
    "str_df_cluster_profile = put_df_on_report(df_cluster_profile.iloc[:,1:], 'Perfil de los grupos')\n",
    "\n",
    "display(HTML(str_df_cluster_profile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series más consultadas por grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:38:25.914535Z",
     "start_time": "2019-08-08T17:38:25.902904Z"
    }
   },
   "outputs": [],
   "source": [
    "df_cluster_unfolded = df_source_unfolded.merge(df_cluster[['ip_address','cluster_name']], on='ip_address', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:38:18.232203Z",
     "start_time": "2019-08-08T17:38:18.178049Z"
    }
   },
   "outputs": [],
   "source": [
    "grouper = df_cluster_unfolded.groupby('cluster_name')\n",
    "counter = grouper.nunique()[['ip_address']].reset_index()\n",
    "clister_ips = counter.sort_values('ip_address')\n",
    "\n",
    "names_sorted = clister_ips.cluster_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:52:12.163589Z",
     "start_time": "2019-08-08T15:45:05.306Z"
    }
   },
   "outputs": [],
   "source": [
    "grouper = df_cluster_unfolded.groupby(['cluster_name','serie_id'] )\n",
    "counter = grouper.count()[['ids']].reset_index()\n",
    "sorter = counter.sort_values(['cluster_name','ids'], ascending=False)\n",
    "\n",
    "head_five = sorter.groupby('cluster_name').head(5)\n",
    "head_five = head_five.merge(df_serie_short, on='serie_id').rename({'serie_id':None}, axis=1)\n",
    "head_five = head_five.set_index(None)\n",
    "\n",
    "head_five.columns = ['cluster_name', 'consultas', 'descripcion', 'fuente_primaria', 'tema', 'frecuencia']\n",
    "\n",
    "str_dfs = ''\n",
    "for n in names_sorted:\n",
    "    filter_n = head_five.cluster_name == n\n",
    "    df = head_five[filter_n].iloc[:,[2,3,4,5,1]].sort_values('consultas',ascending=False)\n",
    "    str_dfs += put_df_on_report(df,title='Grupo {}'.format(n))\n",
    "    str_dfs += '<br><br>'\n",
    "#     display(head_five[filter_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "variables": {
     "str_dfs": {}
    }
   },
   "outputs": [],
   "source": [
    "display(HTML(str_dfs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anexo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuentes primarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:52:12.165769Z",
     "start_time": "2019-08-08T15:45:08.672Z"
    }
   },
   "outputs": [],
   "source": [
    "for c in ['series','consultas']:\n",
    "    new_c = '{}_porcentaje'.format(c)\n",
    "    df_fuentes_features[new_c] = df_fuentes_features[c]/df_fuentes_features[c].sum()*100\n",
    "    \n",
    "nunique_ips = df_source_unfolded.ip_address.nunique()\n",
    "df_fuentes_features['usuarios_porcentaje'] = df_fuentes_features['usuarios'].divide(nunique_ips)*100        \n",
    "\n",
    "aux = add_totals(df_fuentes_features.iloc[:,[0,2,1,5,6,7]].sort_values('consultas', ascending=False))\n",
    "\n",
    "for c in aux.columns[-3:]:\n",
    "        aux[c] = aux[c].apply(lambda x: locale.format_string('%.2f %%', x, 1))\n",
    "\n",
    "aux.iloc[-1,2] = nunique_ips\n",
    "aux.iloc[-1,-1] ='100,00 %'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T15:52:12.166694Z",
     "start_time": "2019-08-08T15:45:09.329Z"
    }
   },
   "outputs": [],
   "source": [
    "str_fuentes = put_df_on_report(aux, 'Fuentes primarias del catálogo SSPM')\n",
    "\n",
    "display(HTML(str_fuentes))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": "0",
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "243.993px",
    "width": "193.507px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "threshold": 4,
   "title_cell": "Indice",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "380px",
    "left": "10px",
    "top": "150px",
    "width": "352.773px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
